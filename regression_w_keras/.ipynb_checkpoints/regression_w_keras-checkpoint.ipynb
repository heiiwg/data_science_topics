{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The link to the article I am following is here.](https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/)\n",
    "\n",
    "The article is written by __Jason Brownlee__ on June 9, 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Tutorial with the Keras Deep Learning Library in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREVIEW:\n",
    "\n",
    "1. Regarding this article my feeling is that it will be similar to the multi-classification problem previously. The only change would be me using a regressor model. \n",
    "2. Instaed of KerasClassifier as the wrapper we will be going to use the KerasRegressor wrapper. \n",
    "3. Cross_val_score will still be used. This is a fundamental concept in testing our data for both classification and regression problems - which also means we will have to configure KFold with shuffle and the seed number.\n",
    "4. A different thing we have to do here is to standardize our dataset becuase the scales of the predictors vary significantly as they measure different things - we did not standardize in the multi-class problem as the variation was not as much as this dataset. \n",
    "5. In this article we test the effect of performance by adding an additional layer to the neural network; and also testing the increase number of neurons to the layer and performance. \n",
    "\n",
    "---\n",
    "\n",
    "As to what the author has to say about point 5:\n",
    "\n",
    "QUOTE: It would have been hard to guess that a wider network would outperform a deeper network on this problem. The results demonstrate the importance of empirical testing when it comes to developing neural network models.\n",
    "\n",
    "1. The author makes the point that empirical testing is central to determining the step you take in machine learning - or anything in general, really. To me, life is all trial and error anyway. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUOTE: We can create Keras models and evaluate them with scikit-learn by using handy wrapper objects provided by the Keras library. This is desirable, because scikit-learn excels at evaluating models and will allow us to use powerful data preparation and model evaluation schemes with very few lines of code.\n",
    "\n",
    "\n",
    "1. The author acknowledges that we wrap Keras model in order to evaluate them using scikit-learn because the model evaluation process in scikit-learn is more concise - we can do it with fewer lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the stuff which you think you will need\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score \n",
    "#cross_val_score is something you use to evaluate your model and thus can be associated to model_selection\n",
    "#KFold is part of cross_val_score thus the same association\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "# remember that scaling is data preprocessing. That's how you remember.\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Pipeline is a whole other concept that is not tied to sklearn.model_selection or sklearn.preprocessing.\n",
    "# The pipeline is a structure to set up the flow of the data from preprocessing to the model training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I need to first tackle this np.random.seed thing. What does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22199317, 0.87073231, 0.20671916, 0.91861091, 0.48841119,\n",
       "       0.61174386, 0.76590786, 0.51841799])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(5) \n",
    "# This initializes the seed.\n",
    "# I assume this is done at the beginning of some process which I want to be repeatable\n",
    "# The author does this seed initialization for each model he creates. \n",
    "# He wants to be able to replicate the results of each model.\n",
    "\n",
    "# I think that is just what it is. To ensure that people who re-do his experiment will be able to replicate the\n",
    "# same results. \n",
    "\n",
    "# He places the seed each time before he does the cross_val_score on the model. \n",
    "\n",
    "# I'm concluding that its just there so someone else can replicate the results that's it. The same calculation - \n",
    "# The same train test split on the same row index so that the model will return the exact same prediction score.\n",
    "\n",
    "np.random.random(8) # this here is the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22199317, 0.87073231, 0.20671916, 0.91861091, 0.48841119,\n",
       "       0.61174386, 0.76590786, 0.51841799])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If I do this random process again with the same seed I will get back the same results.\n",
    "# For example:\n",
    "\n",
    "np.random.seed(5)\n",
    "np.random.random(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you go, the same results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='np.random.seed.png' width=800>\n",
    "\n",
    "[Image taken from the documentation page here](https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.seed.html)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reiterating the whole framework for this modelling process again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the model\n",
    "1. You want to use a Sequential Model \n",
    "    * model = Sequetial()\n",
    "    * model.add(Dense(number_of_neurons, input_dimension, kernel_initilizer, activation_function)\n",
    "    * model.add(Dense(number_of_output_neurons, activation function)\n",
    "    * model.compile(loss=,optimizer, metrics=)\n",
    "    * model.fit(data, labels, epochs, batch_size) # without wrapper cause you are note using sk learn's API for evaluation\n",
    "    * estimator = KerasClassifier(build_fn=built_model, epochs, batch_size, verbose) # using wrapper cause I want to use some functions in sklearn's API on this model. \n",
    "    * KFold(10, shuffle=True, random_state=seed)\n",
    "    * cross_val_score(estimator, X, y, cv=KFold\n",
    "    \n",
    "Set up the data\n",
    "1. load\n",
    "2. Seperate predictors and target, convert to numpy array\n",
    "3. Standardize the predictors if you need to\n",
    "\n",
    "Train the model\n",
    "1. Train using model.fit \n",
    "2. Or use a wrapper and then use scikit-learn's cross_val_score.\n",
    "\n",
    "\n",
    "Evaluate the model\n",
    "\n",
    "---\n",
    "\n",
    "Others:\n",
    "\n",
    "1. kernel_initializer and bias_initializer: The initialization schemes that create the layer's weights (kernel and bias). This parameter is a name or a callable object. This defaults to the \"Glorot uniform\" initializer.\n",
    "\n",
    "\n",
    "Note on cross validation\n",
    "\n",
    "1. QUOTE: __Cross validation is just a method for estimating the performance of a model on unseen data__. It wraps everything you are doing to prepare data and your model, it does not go inside fit.\n",
    "2. This means there is not .predict() method after the cross_val_score becuase cross_val_score does not fit the data onto the model. If you want to use .predict() to see the predicted values then a fitting onto the model has to be done. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The dataset is taken from the kaggle website.](https://www.kaggle.com/c/boston-housing/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "0   1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1   2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2   4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "\n",
       "   ptratio   black  lstat  medv  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     18.7  394.63   2.94  33.4  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./boston_housing_dataset/train.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "\n",
       "    black  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  394.63   2.94  33.4  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('ID', axis=1, inplace=True) #drop the ID column\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 14)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape \n",
    "# 14 features\n",
    "# 333 rows only becuase this is the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Data description is also taken from the Kaggle website](https://www.kaggle.com/c/boston-housing)\n",
    "\n",
    "\n",
    "The Boston data frame has 506 rows and 14 columns.\n",
    "\n",
    "This data frame contains the following columns:\n",
    "\n",
    "__crim__\n",
    "per capita crime rate by town.\n",
    "\n",
    "__zn__\n",
    "proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "\n",
    "__indus__\n",
    "proportion of non-retail business acres per town.\n",
    "\n",
    "__chas__\n",
    "Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "\n",
    "__nox__\n",
    "nitrogen oxides concentration (parts per 10 million).\n",
    "\n",
    "__rm__\n",
    "average number of rooms per dwelling.\n",
    "\n",
    "__age__\n",
    "proportion of owner-occupied units built prior to 1940.\n",
    "\n",
    "__dis__\n",
    "weighted mean of distances to five Boston employment centres.\n",
    "\n",
    "__rad__\n",
    "index of accessibility to radial highways.\n",
    "\n",
    "__tax__\n",
    "full-value property-tax rate per \\$10,000.\n",
    "\n",
    "__ptratio__\n",
    "pupil-teacher ratio by town.\n",
    "\n",
    "__black__\n",
    "1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.\n",
    "\n",
    "__lstat__\n",
    "lower status of the population (percent).\n",
    "\n",
    "__medv__\n",
    "median value of owner-occupied homes in \\$1000s.\n",
    "\n",
    "Thus what we are trying to predict is medv.\n",
    "The median value of all the owner-occupied homes that correspond to these characteristics is this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 3.9690e+02, 4.9800e+00,\n",
       "        2.4000e+01],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 3.9690e+02, 9.1400e+00,\n",
       "        2.1600e+01],\n",
       "       [3.2370e-02, 0.0000e+00, 2.1800e+00, ..., 3.9463e+02, 2.9400e+00,\n",
       "        3.3400e+01],\n",
       "       ...,\n",
       "       [4.5270e-02, 0.0000e+00, 1.1930e+01, ..., 3.9690e+02, 9.0800e+00,\n",
       "        2.0600e+01],\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 3.9690e+02, 5.6400e+00,\n",
       "        2.3900e+01],\n",
       "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 3.9690e+02, 7.8800e+00,\n",
       "        1.1900e+01]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv = df.values \n",
    "dv\n",
    "# this returns an aray. I need this array for cross_val_score. I am assuming becuase the author does this converion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dv[:,:13]\n",
    "y = dv[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 13)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape #columns index 0 to 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape #column index 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First model without standardizing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUOTE: Below we define the function to create the baseline model to be evaluated. It is a simple model that has a single fully connected hidden layer with the same number of neurons as input attributes (13). The network uses good practices such as the rectifier activation function for the hidden layer. No activation function is used for the output layer because it is a regression problem and we are interested in predicting numerical values directly without transform.\n",
    "\n",
    "1. Not sure why author wants the same number of neurons as the input attributes (number of predictors). Maybe it's just a generic thing to create the number number of neurons as your number of predictors.\n",
    "2. He says that the rectifier activation function is a good practice thus I can always assume to put an activation function in the hidden layer. I'm gonna assume its 'relu'. I have done more reading to know if other activations functions should be used than 'relu'.\n",
    "3. No activation function used for the output layer because this is a regression problem because he says that we are do not want to transform the output of these values. \n",
    "\n",
    "I see now. The activation function transforms the values of the output to confrom to the behavior of the function. At some times this helps but as of now we are not looking to transform the values because regression problems require the values as they are. \n",
    "\n",
    "I think I can understand becuase in cases like a logistic regression the range of the values are kept between 0 and 1 and within this range we establish a threshold to determine if we should classify a case as 1 or 0. \n",
    "\n",
    "Thus we are not transforming the values in any way to a given range for some purpose. We want the values to be as it is. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the kernal_initilier?\n",
    "\n",
    "Based on the previous Kearas introduction: kernel_initializer and bias_initializer: \n",
    "\n",
    "The initialization schemes that create the layer's weights (kernel and bias). This parameter is a name or a callable object. __This defaults to the \"Glorot uniform\" initializer.__\n",
    "\n",
    "1. It notes that the initilization creates the layer's weights.\n",
    "\n",
    "On another definition:\n",
    "\n",
    "1. __Initializations define the way to set the initial random weights of Keras layers.__\n",
    "2. For example I can initialize weight values of a certain behavior like a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Image taken from Keras documentation page](https://keras.io/initializers/)\n",
    "<img src='random_normal.png' width=750>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal distribution versus uniform:\n",
    "\n",
    "1. In a random normal distribution, 68% of the values are likely to fall within this range stated on the x-axis, 95% within this range and 99.7% within this range\n",
    "2. In a random uniformation distribution, all value within the range are as likely to be a result. There is not 68%,95% and 99,7% like the random normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# In this normal we initialize the random weights of the keras layers with a normal behavior. The author uses -\n",
    "# so we are just using this. \n",
    "\n",
    "# Interesting that the output neuron is only 1. I remember that we do not use an activation function here on - \n",
    "# the last layer because we do not want to transform the values on the output layer.\n",
    "              \n",
    "# There isn't a metrics parameter for this regression model as well, unsure why. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed) \n",
    "# I'm seeding the random module. This random module must be used somewhere down the line\n",
    "\n",
    "estimator = KerasRegressor(build_fn=sequential, epochs=100, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: \n",
    "\n",
    "__batch_size:__ When passed NumPy data, the model slices the data into smaller batches and iterates over these batches during training. This integer specifies the size of each batch. Be aware that the last batch may be smaller if the total number of samples is not divisible by the batch size.\n",
    "\n",
    "Note that epoch tracks one complete iteration through all the training samples first. Batches are smaller sets of the entire training sample where after the model is done with each batch it updates the weights on the neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Image taken from stack overflow](https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network)\n",
    "\n",
    "In short, less memory needed to train and the training is faster.\n",
    "\n",
    "\n",
    "<img src='batch_size.png' width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 365.7215\n",
      "Epoch 2/100\n",
      "299/299 [==============================] - 0s 347us/step - loss: 144.8585\n",
      "Epoch 3/100\n",
      "299/299 [==============================] - 0s 345us/step - loss: 109.4550\n",
      "Epoch 4/100\n",
      "299/299 [==============================] - 0s 304us/step - loss: 84.8802\n",
      "Epoch 5/100\n",
      "299/299 [==============================] - 0s 319us/step - loss: 78.4198\n",
      "Epoch 6/100\n",
      "299/299 [==============================] - 0s 326us/step - loss: 74.9849\n",
      "Epoch 7/100\n",
      "299/299 [==============================] - 0s 302us/step - loss: 72.7862\n",
      "Epoch 8/100\n",
      "299/299 [==============================] - 0s 336us/step - loss: 73.2192\n",
      "Epoch 9/100\n",
      "299/299 [==============================] - 0s 318us/step - loss: 69.5098\n",
      "Epoch 10/100\n",
      "299/299 [==============================] - 0s 303us/step - loss: 67.4134\n",
      "Epoch 11/100\n",
      "299/299 [==============================] - 0s 340us/step - loss: 66.3938\n",
      "Epoch 12/100\n",
      "299/299 [==============================] - 0s 389us/step - loss: 66.1726\n",
      "Epoch 13/100\n",
      "299/299 [==============================] - 0s 467us/step - loss: 65.8155\n",
      "Epoch 14/100\n",
      "299/299 [==============================] - 0s 417us/step - loss: 63.7898\n",
      "Epoch 15/100\n",
      "299/299 [==============================] - 0s 447us/step - loss: 61.1028\n",
      "Epoch 16/100\n",
      "299/299 [==============================] - 0s 484us/step - loss: 60.9631\n",
      "Epoch 17/100\n",
      "299/299 [==============================] - 0s 483us/step - loss: 59.1080\n",
      "Epoch 18/100\n",
      "299/299 [==============================] - 0s 402us/step - loss: 58.0547\n",
      "Epoch 19/100\n",
      "299/299 [==============================] - 0s 377us/step - loss: 58.8445\n",
      "Epoch 20/100\n",
      "299/299 [==============================] - 0s 324us/step - loss: 57.1004\n",
      "Epoch 21/100\n",
      "299/299 [==============================] - 0s 327us/step - loss: 54.2314\n",
      "Epoch 22/100\n",
      "299/299 [==============================] - 0s 479us/step - loss: 54.2580\n",
      "Epoch 23/100\n",
      "299/299 [==============================] - 0s 406us/step - loss: 52.3772\n",
      "Epoch 24/100\n",
      "299/299 [==============================] - 0s 419us/step - loss: 52.4546\n",
      "Epoch 25/100\n",
      "299/299 [==============================] - 0s 395us/step - loss: 51.0175\n",
      "Epoch 26/100\n",
      "299/299 [==============================] - 0s 409us/step - loss: 50.9222\n",
      "Epoch 27/100\n",
      "299/299 [==============================] - 0s 410us/step - loss: 51.4902\n",
      "Epoch 28/100\n",
      "299/299 [==============================] - 0s 319us/step - loss: 48.7839\n",
      "Epoch 29/100\n",
      "299/299 [==============================] - 0s 324us/step - loss: 46.9317\n",
      "Epoch 30/100\n",
      "299/299 [==============================] - 0s 442us/step - loss: 45.4247\n",
      "Epoch 31/100\n",
      "299/299 [==============================] - 0s 414us/step - loss: 44.9596\n",
      "Epoch 32/100\n",
      "299/299 [==============================] - 0s 395us/step - loss: 45.4881\n",
      "Epoch 33/100\n",
      "299/299 [==============================] - 0s 323us/step - loss: 44.5855\n",
      "Epoch 34/100\n",
      "299/299 [==============================] - 0s 315us/step - loss: 42.5726\n",
      "Epoch 35/100\n",
      "299/299 [==============================] - 0s 311us/step - loss: 43.5248\n",
      "Epoch 36/100\n",
      "299/299 [==============================] - 0s 310us/step - loss: 41.4941\n",
      "Epoch 37/100\n",
      "299/299 [==============================] - 0s 338us/step - loss: 41.5313\n",
      "Epoch 38/100\n",
      "299/299 [==============================] - 0s 363us/step - loss: 41.4488\n",
      "Epoch 39/100\n",
      "299/299 [==============================] - 0s 389us/step - loss: 40.8499\n",
      "Epoch 40/100\n",
      "299/299 [==============================] - 0s 310us/step - loss: 42.2971\n",
      "Epoch 41/100\n",
      "299/299 [==============================] - 0s 308us/step - loss: 39.8373\n",
      "Epoch 42/100\n",
      "299/299 [==============================] - 0s 434us/step - loss: 39.9430\n",
      "Epoch 43/100\n",
      "299/299 [==============================] - 0s 403us/step - loss: 39.7089\n",
      "Epoch 44/100\n",
      "299/299 [==============================] - 0s 417us/step - loss: 41.0250\n",
      "Epoch 45/100\n",
      "299/299 [==============================] - 0s 322us/step - loss: 38.4524\n",
      "Epoch 46/100\n",
      "299/299 [==============================] - 0s 312us/step - loss: 39.0119\n",
      "Epoch 47/100\n",
      "299/299 [==============================] - 0s 318us/step - loss: 38.2381\n",
      "Epoch 48/100\n",
      "299/299 [==============================] - 0s 311us/step - loss: 37.7776\n",
      "Epoch 49/100\n",
      "299/299 [==============================] - 0s 313us/step - loss: 38.6329\n",
      "Epoch 50/100\n",
      "299/299 [==============================] - 0s 360us/step - loss: 37.6877\n",
      "Epoch 51/100\n",
      "299/299 [==============================] - 0s 384us/step - loss: 39.7029\n",
      "Epoch 52/100\n",
      "299/299 [==============================] - 0s 463us/step - loss: 37.7578\n",
      "Epoch 53/100\n",
      "299/299 [==============================] - 0s 340us/step - loss: 38.0647\n",
      "Epoch 54/100\n",
      "299/299 [==============================] - 0s 323us/step - loss: 38.2552\n",
      "Epoch 55/100\n",
      "299/299 [==============================] - 0s 341us/step - loss: 39.9103\n",
      "Epoch 56/100\n",
      "299/299 [==============================] - 0s 319us/step - loss: 37.7868\n",
      "Epoch 57/100\n",
      "299/299 [==============================] - 0s 305us/step - loss: 37.2849\n",
      "Epoch 58/100\n",
      "299/299 [==============================] - 0s 308us/step - loss: 36.5732\n",
      "Epoch 59/100\n",
      "299/299 [==============================] - 0s 303us/step - loss: 36.5461\n",
      "Epoch 60/100\n",
      "299/299 [==============================] - 0s 432us/step - loss: 36.1948\n",
      "Epoch 61/100\n",
      "299/299 [==============================] - 0s 462us/step - loss: 38.8560\n",
      "Epoch 62/100\n",
      "299/299 [==============================] - 0s 448us/step - loss: 36.4770\n",
      "Epoch 63/100\n",
      "299/299 [==============================] - 0s 453us/step - loss: 37.7087\n",
      "Epoch 64/100\n",
      "299/299 [==============================] - 0s 323us/step - loss: 37.1993\n",
      "Epoch 65/100\n",
      "299/299 [==============================] - 0s 305us/step - loss: 37.3482\n",
      "Epoch 66/100\n",
      "299/299 [==============================] - 0s 314us/step - loss: 35.8203\n",
      "Epoch 67/100\n",
      "299/299 [==============================] - 0s 298us/step - loss: 36.8601\n",
      "Epoch 68/100\n",
      "299/299 [==============================] - 0s 304us/step - loss: 36.0649\n",
      "Epoch 69/100\n",
      "299/299 [==============================] - 0s 482us/step - loss: 36.9391\n",
      "Epoch 70/100\n",
      "299/299 [==============================] - 0s 443us/step - loss: 36.9777\n",
      "Epoch 71/100\n",
      "299/299 [==============================] - 0s 421us/step - loss: 36.0388\n",
      "Epoch 72/100\n",
      "299/299 [==============================] - 0s 422us/step - loss: 35.7025\n",
      "Epoch 73/100\n",
      "299/299 [==============================] - 0s 403us/step - loss: 35.2073\n",
      "Epoch 74/100\n",
      "299/299 [==============================] - 0s 356us/step - loss: 35.1408\n",
      "Epoch 75/100\n",
      "299/299 [==============================] - 0s 457us/step - loss: 35.3129\n",
      "Epoch 76/100\n",
      "299/299 [==============================] - 0s 414us/step - loss: 34.9643\n",
      "Epoch 77/100\n",
      "299/299 [==============================] - 0s 427us/step - loss: 35.5871\n",
      "Epoch 78/100\n",
      "299/299 [==============================] - 0s 398us/step - loss: 35.0303\n",
      "Epoch 79/100\n",
      "299/299 [==============================] - 0s 482us/step - loss: 35.5463\n",
      "Epoch 80/100\n",
      "299/299 [==============================] - 0s 445us/step - loss: 33.8651\n",
      "Epoch 81/100\n",
      "299/299 [==============================] - 0s 438us/step - loss: 35.5560\n",
      "Epoch 82/100\n",
      "299/299 [==============================] - 0s 443us/step - loss: 34.7479\n",
      "Epoch 83/100\n",
      "299/299 [==============================] - 0s 318us/step - loss: 34.7523\n",
      "Epoch 84/100\n",
      "299/299 [==============================] - 0s 317us/step - loss: 36.4166\n",
      "Epoch 85/100\n",
      "299/299 [==============================] - 0s 459us/step - loss: 34.5553\n",
      "Epoch 86/100\n",
      "299/299 [==============================] - 0s 327us/step - loss: 34.0984\n",
      "Epoch 87/100\n",
      "299/299 [==============================] - 0s 305us/step - loss: 34.6414\n",
      "Epoch 88/100\n",
      "299/299 [==============================] - 0s 334us/step - loss: 36.7770\n",
      "Epoch 89/100\n",
      "299/299 [==============================] - 0s 342us/step - loss: 37.7029\n",
      "Epoch 90/100\n",
      "299/299 [==============================] - 0s 311us/step - loss: 33.8350\n",
      "Epoch 91/100\n",
      "299/299 [==============================] - 0s 398us/step - loss: 33.5547\n",
      "Epoch 92/100\n",
      "299/299 [==============================] - 0s 481us/step - loss: 34.5211\n",
      "Epoch 93/100\n",
      "299/299 [==============================] - 0s 410us/step - loss: 34.5551\n",
      "Epoch 94/100\n",
      "299/299 [==============================] - 0s 337us/step - loss: 33.8931\n",
      "Epoch 95/100\n",
      "299/299 [==============================] - 0s 346us/step - loss: 33.9365\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 0s 430us/step - loss: 35.1947\n",
      "Epoch 97/100\n",
      "299/299 [==============================] - 0s 377us/step - loss: 35.7268\n",
      "Epoch 98/100\n",
      "299/299 [==============================] - 0s 438us/step - loss: 32.9954\n",
      "Epoch 99/100\n",
      "299/299 [==============================] - 0s 426us/step - loss: 33.8521\n",
      "Epoch 100/100\n",
      "299/299 [==============================] - 0s 399us/step - loss: 33.4114\n",
      "34/34 [==============================] - 1s 18ms/step\n",
      "Epoch 1/100\n",
      "299/299 [==============================] - 2s 6ms/step - loss: 203.2500\n",
      "Epoch 2/100\n",
      "299/299 [==============================] - 0s 302us/step - loss: 94.7641\n",
      "Epoch 3/100\n",
      "299/299 [==============================] - 0s 300us/step - loss: 76.2690\n",
      "Epoch 4/100\n",
      "299/299 [==============================] - 0s 309us/step - loss: 69.3784\n",
      "Epoch 5/100\n",
      "299/299 [==============================] - 0s 308us/step - loss: 66.1817\n",
      "Epoch 6/100\n",
      "299/299 [==============================] - 0s 313us/step - loss: 63.9747\n",
      "Epoch 7/100\n",
      "299/299 [==============================] - 0s 323us/step - loss: 61.6286\n",
      "Epoch 8/100\n",
      "299/299 [==============================] - 0s 369us/step - loss: 60.8857\n",
      "Epoch 9/100\n",
      "299/299 [==============================] - 0s 369us/step - loss: 59.9284\n",
      "Epoch 10/100\n",
      "299/299 [==============================] - 0s 311us/step - loss: 58.5169\n",
      "Epoch 11/100\n",
      "299/299 [==============================] - 0s 305us/step - loss: 57.7284\n",
      "Epoch 12/100\n",
      "299/299 [==============================] - 0s 301us/step - loss: 56.3459\n",
      "Epoch 13/100\n",
      "299/299 [==============================] - 0s 308us/step - loss: 55.8649\n",
      "Epoch 14/100\n",
      "299/299 [==============================] - 0s 310us/step - loss: 53.3296\n",
      "Epoch 15/100\n",
      "299/299 [==============================] - 0s 303us/step - loss: 52.5491\n",
      "Epoch 16/100\n",
      "299/299 [==============================] - 0s 316us/step - loss: 51.4455\n",
      "Epoch 17/100\n",
      "299/299 [==============================] - 0s 304us/step - loss: 49.6704\n",
      "Epoch 18/100\n",
      "299/299 [==============================] - 0s 308us/step - loss: 49.2378\n",
      "Epoch 19/100\n",
      "299/299 [==============================] - 0s 313us/step - loss: 47.4148\n",
      "Epoch 20/100\n",
      "299/299 [==============================] - 0s 307us/step - loss: 47.2784\n",
      "Epoch 21/100\n",
      "299/299 [==============================] - 0s 318us/step - loss: 46.2475\n",
      "Epoch 22/100\n",
      "299/299 [==============================] - 0s 300us/step - loss: 46.4595\n",
      "Epoch 23/100\n",
      "299/299 [==============================] - 0s 310us/step - loss: 44.6402\n",
      "Epoch 24/100\n",
      "299/299 [==============================] - 0s 335us/step - loss: 42.1942\n",
      "Epoch 25/100\n",
      "299/299 [==============================] - 0s 346us/step - loss: 41.3465\n",
      "Epoch 26/100\n",
      "299/299 [==============================] - 0s 343us/step - loss: 41.3226\n",
      "Epoch 27/100\n",
      "299/299 [==============================] - 0s 337us/step - loss: 41.7669\n",
      "Epoch 28/100\n",
      "299/299 [==============================] - 0s 342us/step - loss: 40.2609\n",
      "Epoch 29/100\n",
      "299/299 [==============================] - 0s 339us/step - loss: 40.0168\n",
      "Epoch 30/100\n",
      "299/299 [==============================] - 0s 314us/step - loss: 37.4926\n",
      "Epoch 31/100\n",
      "299/299 [==============================] - 0s 306us/step - loss: 37.2740\n",
      "Epoch 32/100\n",
      "299/299 [==============================] - 0s 377us/step - loss: 37.7850\n",
      "Epoch 33/100\n",
      "299/299 [==============================] - 0s 325us/step - loss: 36.6653\n",
      "Epoch 34/100\n",
      "299/299 [==============================] - 0s 353us/step - loss: 35.8074\n",
      "Epoch 35/100\n",
      "299/299 [==============================] - 0s 352us/step - loss: 36.0057\n",
      "Epoch 36/100\n",
      "299/299 [==============================] - 0s 466us/step - loss: 35.2719\n",
      "Epoch 37/100\n",
      "299/299 [==============================] - 0s 414us/step - loss: 36.7529\n",
      "Epoch 38/100\n",
      "299/299 [==============================] - 0s 330us/step - loss: 34.2188\n",
      "Epoch 39/100\n",
      "299/299 [==============================] - 0s 448us/step - loss: 35.9222\n",
      "Epoch 40/100\n",
      "299/299 [==============================] - 0s 425us/step - loss: 32.7764\n",
      "Epoch 41/100\n",
      "299/299 [==============================] - 0s 400us/step - loss: 32.7967\n",
      "Epoch 42/100\n",
      "299/299 [==============================] - 0s 426us/step - loss: 33.2612\n",
      "Epoch 43/100\n",
      "299/299 [==============================] - 0s 360us/step - loss: 33.4920\n",
      "Epoch 44/100\n",
      "299/299 [==============================] - 0s 327us/step - loss: 32.5706\n",
      "Epoch 45/100\n",
      "299/299 [==============================] - 0s 319us/step - loss: 31.1908\n",
      "Epoch 46/100\n",
      "299/299 [==============================] - 0s 317us/step - loss: 30.4311\n",
      "Epoch 47/100\n",
      "299/299 [==============================] - 0s 322us/step - loss: 30.4050\n",
      "Epoch 48/100\n",
      "299/299 [==============================] - 0s 342us/step - loss: 29.5785\n",
      "Epoch 49/100\n",
      "299/299 [==============================] - 0s 385us/step - loss: 30.0748\n",
      "Epoch 50/100\n",
      "299/299 [==============================] - 0s 344us/step - loss: 28.0517\n",
      "Epoch 51/100\n",
      "299/299 [==============================] - 0s 371us/step - loss: 29.1152\n",
      "Epoch 52/100\n",
      "299/299 [==============================] - 0s 438us/step - loss: 29.4654\n",
      "Epoch 53/100\n",
      "299/299 [==============================] - 0s 330us/step - loss: 28.6795\n",
      "Epoch 54/100\n",
      "299/299 [==============================] - 0s 426us/step - loss: 28.5855\n",
      "Epoch 55/100\n",
      "299/299 [==============================] - 0s 314us/step - loss: 31.5061\n",
      "Epoch 56/100\n",
      "299/299 [==============================] - 0s 317us/step - loss: 29.9185\n",
      "Epoch 57/100\n",
      "299/299 [==============================] - 0s 326us/step - loss: 27.2370\n",
      "Epoch 58/100\n",
      "299/299 [==============================] - 0s 380us/step - loss: 26.9274\n",
      "Epoch 59/100\n",
      "299/299 [==============================] - 0s 369us/step - loss: 30.3303\n",
      "Epoch 60/100\n",
      "299/299 [==============================] - 0s 329us/step - loss: 27.4828\n",
      "Epoch 61/100\n",
      "299/299 [==============================] - 0s 409us/step - loss: 26.4370\n",
      "Epoch 62/100\n",
      "299/299 [==============================] - 0s 375us/step - loss: 26.2123\n",
      "Epoch 63/100\n",
      "299/299 [==============================] - 0s 326us/step - loss: 26.9453\n",
      "Epoch 64/100\n",
      "299/299 [==============================] - 0s 317us/step - loss: 25.2026\n",
      "Epoch 65/100\n",
      "299/299 [==============================] - 0s 319us/step - loss: 26.0604\n",
      "Epoch 66/100\n",
      "299/299 [==============================] - 0s 318us/step - loss: 25.8912\n",
      "Epoch 67/100\n",
      "299/299 [==============================] - 0s 316us/step - loss: 25.0193\n",
      "Epoch 68/100\n",
      "299/299 [==============================] - 0s 325us/step - loss: 26.4819\n",
      "Epoch 69/100\n",
      "299/299 [==============================] - 0s 320us/step - loss: 24.1254\n",
      "Epoch 70/100\n",
      "299/299 [==============================] - 0s 328us/step - loss: 24.2708\n",
      "Epoch 71/100\n",
      "299/299 [==============================] - 0s 323us/step - loss: 23.9092\n",
      "Epoch 72/100\n",
      "299/299 [==============================] - 0s 320us/step - loss: 23.8384\n",
      "Epoch 73/100\n",
      "299/299 [==============================] - 0s 320us/step - loss: 24.9578\n",
      "Epoch 74/100\n",
      "299/299 [==============================] - 0s 315us/step - loss: 22.9229\n",
      "Epoch 75/100\n",
      "299/299 [==============================] - 0s 312us/step - loss: 23.3359\n",
      "Epoch 76/100\n",
      "299/299 [==============================] - 0s 318us/step - loss: 22.3753\n",
      "Epoch 77/100\n",
      "299/299 [==============================] - 0s 314us/step - loss: 25.7980\n",
      "Epoch 78/100\n",
      "299/299 [==============================] - 0s 319us/step - loss: 23.1233\n",
      "Epoch 79/100\n",
      "299/299 [==============================] - 0s 323us/step - loss: 20.8678\n",
      "Epoch 80/100\n",
      "299/299 [==============================] - 0s 317us/step - loss: 22.8652\n",
      "Epoch 81/100\n",
      "299/299 [==============================] - 0s 318us/step - loss: 21.4722\n",
      "Epoch 82/100\n",
      "299/299 [==============================] - 0s 321us/step - loss: 22.7249\n",
      "Epoch 83/100\n",
      "299/299 [==============================] - 0s 326us/step - loss: 22.8281\n",
      "Epoch 84/100\n",
      "299/299 [==============================] - 0s 316us/step - loss: 24.1802\n",
      "Epoch 85/100\n",
      "299/299 [==============================] - 0s 318us/step - loss: 22.2281\n",
      "Epoch 86/100\n",
      "299/299 [==============================] - 0s 318us/step - loss: 22.3777\n",
      "Epoch 87/100\n",
      "299/299 [==============================] - 0s 325us/step - loss: 22.3984\n",
      "Epoch 88/100\n",
      "299/299 [==============================] - 0s 313us/step - loss: 21.9739\n",
      "Epoch 89/100\n",
      "299/299 [==============================] - 0s 318us/step - loss: 22.4704\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 0s 327us/step - loss: 22.3147\n",
      "Epoch 91/100\n",
      "299/299 [==============================] - 0s 301us/step - loss: 20.5150\n",
      "Epoch 92/100\n",
      "299/299 [==============================] - 0s 298us/step - loss: 21.6739\n",
      "Epoch 93/100\n",
      "299/299 [==============================] - 0s 298us/step - loss: 20.9592\n",
      "Epoch 94/100\n",
      "299/299 [==============================] - 0s 307us/step - loss: 23.7513\n",
      "Epoch 95/100\n",
      "299/299 [==============================] - 0s 300us/step - loss: 21.1369\n",
      "Epoch 96/100\n",
      "299/299 [==============================] - 0s 305us/step - loss: 21.2856\n",
      "Epoch 97/100\n",
      "299/299 [==============================] - 0s 406us/step - loss: 21.6437\n",
      "Epoch 98/100\n",
      "299/299 [==============================] - 0s 395us/step - loss: 20.7315\n",
      "Epoch 99/100\n",
      "299/299 [==============================] - 0s 377us/step - loss: 21.6902\n",
      "Epoch 100/100\n",
      "299/299 [==============================] - 0s 380us/step - loss: 20.5238\n",
      "34/34 [==============================] - 1s 20ms/step\n",
      "Epoch 1/100\n",
      "299/299 [==============================] - 2s 6ms/step - loss: 309.9986\n",
      "Epoch 2/100\n",
      "299/299 [==============================] - 0s 305us/step - loss: 129.1142\n",
      "Epoch 3/100\n",
      "299/299 [==============================] - 0s 413us/step - loss: 89.8141\n",
      "Epoch 4/100\n",
      "299/299 [==============================] - 0s 406us/step - loss: 77.4019\n",
      "Epoch 5/100\n",
      "299/299 [==============================] - 0s 314us/step - loss: 70.0581\n",
      "Epoch 6/100\n",
      "299/299 [==============================] - 0s 304us/step - loss: 69.0628\n",
      "Epoch 7/100\n",
      "299/299 [==============================] - 0s 400us/step - loss: 65.5937\n",
      "Epoch 8/100\n",
      "299/299 [==============================] - 0s 417us/step - loss: 63.2404\n",
      "Epoch 9/100\n",
      "299/299 [==============================] - 0s 324us/step - loss: 63.6109\n",
      "Epoch 10/100\n",
      "299/299 [==============================] - 0s 303us/step - loss: 61.2428\n",
      "Epoch 11/100\n",
      "299/299 [==============================] - 0s 304us/step - loss: 60.2338\n",
      "Epoch 12/100\n",
      "299/299 [==============================] - 0s 307us/step - loss: 58.5194\n",
      "Epoch 13/100\n",
      "299/299 [==============================] - 0s 304us/step - loss: 57.4725\n",
      "Epoch 14/100\n",
      "299/299 [==============================] - 0s 357us/step - loss: 59.2391\n",
      "Epoch 15/100\n",
      "299/299 [==============================] - 0s 347us/step - loss: 55.3279\n",
      "Epoch 16/100\n",
      "299/299 [==============================] - 0s 327us/step - loss: 54.5155\n",
      "Epoch 17/100\n",
      "299/299 [==============================] - 0s 456us/step - loss: 53.8925\n",
      "Epoch 18/100\n",
      "299/299 [==============================] - 0s 384us/step - loss: 51.3399\n",
      "Epoch 19/100\n",
      "299/299 [==============================] - 0s 339us/step - loss: 51.6871\n",
      "Epoch 20/100\n",
      "299/299 [==============================] - 0s 308us/step - loss: 50.0506\n",
      "Epoch 21/100\n",
      "299/299 [==============================] - 0s 322us/step - loss: 48.4966\n",
      "Epoch 22/100\n",
      "299/299 [==============================] - 0s 309us/step - loss: 47.4017\n",
      "Epoch 23/100\n",
      "299/299 [==============================] - 0s 314us/step - loss: 46.2083\n",
      "Epoch 24/100\n",
      "299/299 [==============================] - 0s 416us/step - loss: 45.4495\n",
      "Epoch 25/100\n",
      "299/299 [==============================] - 0s 392us/step - loss: 44.4251\n",
      "Epoch 26/100\n",
      "299/299 [==============================] - 0s 318us/step - loss: 43.7206\n",
      "Epoch 27/100\n",
      "299/299 [==============================] - 0s 326us/step - loss: 41.4479\n",
      "Epoch 28/100\n",
      "299/299 [==============================] - 0s 328us/step - loss: 41.7003\n",
      "Epoch 29/100\n",
      "299/299 [==============================] - 0s 358us/step - loss: 41.7461\n",
      "Epoch 30/100\n",
      "299/299 [==============================] - 0s 305us/step - loss: 40.3667\n",
      "Epoch 31/100\n",
      "299/299 [==============================] - 0s 313us/step - loss: 39.8436\n",
      "Epoch 32/100\n",
      "299/299 [==============================] - 0s 354us/step - loss: 38.6498\n",
      "Epoch 33/100\n",
      "299/299 [==============================] - 0s 323us/step - loss: 39.0057\n",
      "Epoch 34/100\n",
      "299/299 [==============================] - 0s 296us/step - loss: 38.5820\n",
      "Epoch 35/100\n",
      "299/299 [==============================] - 0s 299us/step - loss: 36.5986\n",
      "Epoch 36/100\n",
      "299/299 [==============================] - 0s 309us/step - loss: 36.0045\n",
      "Epoch 37/100\n",
      "299/299 [==============================] - 0s 383us/step - loss: 35.1042\n",
      "Epoch 38/100\n",
      "299/299 [==============================] - 0s 310us/step - loss: 36.9446\n",
      "Epoch 39/100\n",
      "299/299 [==============================] - 0s 308us/step - loss: 36.3703\n",
      "Epoch 40/100\n",
      "299/299 [==============================] - 0s 326us/step - loss: 34.0684\n",
      "Epoch 41/100\n",
      "299/299 [==============================] - 0s 327us/step - loss: 34.4839\n",
      "Epoch 42/100\n",
      "299/299 [==============================] - 0s 302us/step - loss: 33.7248\n",
      "Epoch 43/100\n",
      "299/299 [==============================] - 0s 328us/step - loss: 33.6507\n",
      "Epoch 44/100\n",
      "299/299 [==============================] - 0s 356us/step - loss: 33.2072\n",
      "Epoch 45/100\n",
      "299/299 [==============================] - 0s 347us/step - loss: 32.3862\n",
      "Epoch 46/100\n",
      "299/299 [==============================] - 0s 308us/step - loss: 32.5808\n",
      "Epoch 47/100\n",
      "299/299 [==============================] - 0s 312us/step - loss: 33.2101\n",
      "Epoch 48/100\n",
      "299/299 [==============================] - 0s 313us/step - loss: 32.0577\n",
      "Epoch 49/100\n",
      "299/299 [==============================] - 0s 318us/step - loss: 31.8974\n",
      "Epoch 50/100\n",
      "299/299 [==============================] - 0s 298us/step - loss: 30.7127\n",
      "Epoch 51/100\n",
      "299/299 [==============================] - 0s 297us/step - loss: 31.4512\n",
      "Epoch 52/100\n",
      "299/299 [==============================] - 0s 303us/step - loss: 32.0121\n",
      "Epoch 53/100\n",
      "299/299 [==============================] - 0s 295us/step - loss: 31.2384\n",
      "Epoch 54/100\n",
      "299/299 [==============================] - 0s 297us/step - loss: 31.6340\n",
      "Epoch 55/100\n",
      "299/299 [==============================] - 0s 302us/step - loss: 30.4193\n",
      "Epoch 56/100\n",
      "299/299 [==============================] - 0s 298us/step - loss: 31.3464\n",
      "Epoch 57/100\n",
      "299/299 [==============================] - 0s 301us/step - loss: 29.9938\n",
      "Epoch 58/100\n",
      "299/299 [==============================] - 0s 299us/step - loss: 31.1615\n",
      "Epoch 59/100\n",
      "299/299 [==============================] - 0s 297us/step - loss: 32.1090\n",
      "Epoch 60/100\n",
      "299/299 [==============================] - 0s 298us/step - loss: 30.3788\n",
      "Epoch 61/100\n",
      "299/299 [==============================] - 0s 300us/step - loss: 29.9729\n",
      "Epoch 62/100\n",
      "299/299 [==============================] - 0s 306us/step - loss: 29.3443\n",
      "Epoch 63/100\n",
      "299/299 [==============================] - 0s 300us/step - loss: 30.3381\n",
      "Epoch 64/100\n",
      "299/299 [==============================] - 0s 309us/step - loss: 30.9122\n",
      "Epoch 65/100\n",
      "299/299 [==============================] - 0s 299us/step - loss: 29.4041\n",
      "Epoch 66/100\n",
      "299/299 [==============================] - 0s 310us/step - loss: 29.3860\n",
      "Epoch 67/100\n",
      "299/299 [==============================] - 0s 296us/step - loss: 30.6629\n",
      "Epoch 68/100\n",
      "299/299 [==============================] - 0s 294us/step - loss: 27.5843\n",
      "Epoch 69/100\n",
      "299/299 [==============================] - 0s 300us/step - loss: 29.0626\n",
      "Epoch 70/100\n",
      "299/299 [==============================] - 0s 296us/step - loss: 28.3440\n",
      "Epoch 71/100\n",
      "299/299 [==============================] - 0s 311us/step - loss: 28.4733\n",
      "Epoch 72/100\n",
      "299/299 [==============================] - 0s 307us/step - loss: 27.2555\n",
      "Epoch 73/100\n",
      "299/299 [==============================] - 0s 297us/step - loss: 26.7819\n",
      "Epoch 74/100\n",
      "299/299 [==============================] - 0s 303us/step - loss: 26.9402\n",
      "Epoch 75/100\n",
      "299/299 [==============================] - 0s 306us/step - loss: 26.5856\n",
      "Epoch 76/100\n",
      "299/299 [==============================] - 0s 298us/step - loss: 26.9817\n",
      "Epoch 77/100\n",
      "299/299 [==============================] - 0s 307us/step - loss: 26.4371\n",
      "Epoch 78/100\n",
      "299/299 [==============================] - 0s 363us/step - loss: 26.2318\n",
      "Epoch 79/100\n",
      "299/299 [==============================] - 0s 309us/step - loss: 25.6214\n",
      "Epoch 80/100\n",
      "299/299 [==============================] - 0s 299us/step - loss: 28.2033\n",
      "Epoch 81/100\n",
      "299/299 [==============================] - 0s 306us/step - loss: 25.6768\n",
      "Epoch 82/100\n",
      "299/299 [==============================] - 0s 300us/step - loss: 25.3142\n",
      "Epoch 83/100\n",
      "299/299 [==============================] - 0s 382us/step - loss: 26.2807\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 0s 401us/step - loss: 25.6085\n",
      "Epoch 85/100\n",
      "299/299 [==============================] - 0s 301us/step - loss: 26.8227\n",
      "Epoch 86/100\n",
      "299/299 [==============================] - 0s 298us/step - loss: 26.2752\n",
      "Epoch 87/100\n",
      "299/299 [==============================] - 0s 297us/step - loss: 27.7214\n",
      "Epoch 88/100\n",
      "299/299 [==============================] - 0s 294us/step - loss: 28.0872\n",
      "Epoch 89/100\n",
      "299/299 [==============================] - 0s 302us/step - loss: 23.3353\n",
      "Epoch 90/100\n",
      "299/299 [==============================] - 0s 385us/step - loss: 28.2561\n",
      "Epoch 91/100\n",
      "299/299 [==============================] - 0s 399us/step - loss: 24.8265\n",
      "Epoch 92/100\n",
      "299/299 [==============================] - 0s 486us/step - loss: 24.0071\n",
      "Epoch 93/100\n",
      "299/299 [==============================] - 0s 471us/step - loss: 25.5412\n",
      "Epoch 94/100\n",
      "299/299 [==============================] - 0s 424us/step - loss: 23.0228\n",
      "Epoch 95/100\n",
      "299/299 [==============================] - 0s 493us/step - loss: 25.6238\n",
      "Epoch 96/100\n",
      "299/299 [==============================] - 0s 444us/step - loss: 25.1850\n",
      "Epoch 97/100\n",
      "299/299 [==============================] - 0s 416us/step - loss: 23.4607\n",
      "Epoch 98/100\n",
      "299/299 [==============================] - 0s 314us/step - loss: 24.0240\n",
      "Epoch 99/100\n",
      "299/299 [==============================] - 0s 491us/step - loss: 24.6045\n",
      "Epoch 100/100\n",
      "299/299 [==============================] - 0s 314us/step - loss: 23.6088\n",
      "34/34 [==============================] - 1s 18ms/step\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 239.1879\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 0s 314us/step - loss: 94.6420\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 0s 304us/step - loss: 74.0220\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 0s 302us/step - loss: 66.3453\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 0s 303us/step - loss: 62.3264\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 0s 301us/step - loss: 58.5744\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 0s 311us/step - loss: 55.8963\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 0s 311us/step - loss: 54.8869\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 0s 357us/step - loss: 53.3508\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 0s 320us/step - loss: 52.4753\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 0s 301us/step - loss: 51.3228\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 0s 374us/step - loss: 50.8241\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 0s 463us/step - loss: 50.7249\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 49.5835\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 0s 312us/step - loss: 48.1215\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 0s 309us/step - loss: 48.7078\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 0s 308us/step - loss: 47.2762\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 0s 312us/step - loss: 46.3928\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 0s 308us/step - loss: 45.6016\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 0s 322us/step - loss: 45.2842\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 0s 316us/step - loss: 46.3848\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 0s 306us/step - loss: 46.4550\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 0s 303us/step - loss: 44.7562\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 0s 310us/step - loss: 42.1171\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 0s 305us/step - loss: 41.7574\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 0s 305us/step - loss: 41.1141\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 0s 306us/step - loss: 40.4313\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 0s 304us/step - loss: 40.0852\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 0s 303us/step - loss: 38.6578\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 0s 313us/step - loss: 39.1308\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 0s 306us/step - loss: 36.9651\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 0s 311us/step - loss: 36.2492\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 0s 308us/step - loss: 36.3298\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 0s 306us/step - loss: 37.0144\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 0s 315us/step - loss: 34.9237\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 0s 309us/step - loss: 34.7473\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 0s 305us/step - loss: 34.3231\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 0s 306us/step - loss: 33.2536\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 0s 308us/step - loss: 32.9817\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 0s 322us/step - loss: 32.6617\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 0s 438us/step - loss: 33.6285\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 0s 419us/step - loss: 33.0329\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 0s 401us/step - loss: 32.5823\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 0s 418us/step - loss: 31.6125\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 0s 423us/step - loss: 32.2062\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 0s 415us/step - loss: 30.8875\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 0s 399us/step - loss: 30.6823\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 0s 407us/step - loss: 30.5840\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 0s 406us/step - loss: 30.6770\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 0s 408us/step - loss: 29.7462\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 0s 408us/step - loss: 30.1020\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 30.4399\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 0s 465us/step - loss: 29.8954\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 28.7412\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 29.9623\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 0s 362us/step - loss: 29.0802\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 0s 343us/step - loss: 28.3774\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 0s 401us/step - loss: 27.2654\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 0s 454us/step - loss: 27.7336\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 0s 322us/step - loss: 28.4414\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 0s 364us/step - loss: 27.2249\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 0s 404us/step - loss: 27.8243\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 0s 439us/step - loss: 27.3771\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 0s 389us/step - loss: 26.6507\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 27.4813\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 0s 324us/step - loss: 27.9128\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 0s 323us/step - loss: 25.9231\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 0s 318us/step - loss: 26.2431\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 0s 371us/step - loss: 26.0736\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 0s 388us/step - loss: 25.6760\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 0s 464us/step - loss: 26.2035\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 0s 448us/step - loss: 26.8042\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 0s 420us/step - loss: 25.5637\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 0s 419us/step - loss: 23.8905\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 0s 396us/step - loss: 24.5949\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 0s 352us/step - loss: 24.7099\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 0s 363us/step - loss: 23.9112\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 454us/step - loss: 23.9746\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 0s 440us/step - loss: 23.6219\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 0s 391us/step - loss: 24.7251\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 0s 393us/step - loss: 23.2199\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 0s 406us/step - loss: 24.8026\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 0s 323us/step - loss: 23.3900\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 0s 404us/step - loss: 22.9663\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 0s 393us/step - loss: 22.0629\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 0s 317us/step - loss: 23.4009\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 0s 406us/step - loss: 22.6800\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 0s 497us/step - loss: 22.7601\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 0s 516us/step - loss: 22.0316\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 0s 460us/step - loss: 22.9040\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 0s 351us/step - loss: 21.1431\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 0s 344us/step - loss: 21.4083\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 0s 444us/step - loss: 21.1433\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 0s 429us/step - loss: 20.9303\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 0s 345us/step - loss: 21.5315\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 0s 362us/step - loss: 21.1821\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 0s 364us/step - loss: 22.2812\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 0s 304us/step - loss: 22.1220\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 0s 372us/step - loss: 23.9159\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 0s 400us/step - loss: 21.6751\n",
      "33/33 [==============================] - 1s 23ms/step\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 474.4921\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 196.4349\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 0s 362us/step - loss: 124.8256 0s - loss: 126.364\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 0s 478us/step - loss: 107.8985\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 91.3110\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 0s 321us/step - loss: 78.5727\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 0s 367us/step - loss: 71.4477\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 0s 437us/step - loss: 67.5504\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 0s 355us/step - loss: 67.8548\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 0s 316us/step - loss: 68.8465\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 0s 354us/step - loss: 65.0369\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 0s 494us/step - loss: 64.4340\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 0s 419us/step - loss: 63.4748\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 0s 323us/step - loss: 63.3297\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 64.0131\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 61.7730\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 62.5378\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 0s 353us/step - loss: 61.1374\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 61.2929\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 0s 324us/step - loss: 60.3573\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 0s 326us/step - loss: 59.1972\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 0s 323us/step - loss: 61.2893\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 0s 326us/step - loss: 58.9581\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 59.8211\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 57.6090\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 0s 384us/step - loss: 57.9243\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 0s 371us/step - loss: 56.8229\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 0s 372us/step - loss: 56.6156\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 55.5415\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 0s 319us/step - loss: 55.8309\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 0s 407us/step - loss: 54.6651\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 0s 563us/step - loss: 56.0694\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 0s 597us/step - loss: 54.6849\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 0s 557us/step - loss: 54.3174\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 0s 548us/step - loss: 53.3609\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 0s 576us/step - loss: 52.8310\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 0s 544us/step - loss: 52.3978\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 0s 549us/step - loss: 51.7386\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 0s 534us/step - loss: 51.8029\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 0s 424us/step - loss: 50.0134\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 52.5354\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 0s 359us/step - loss: 49.6611\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 51.3834\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 0s 466us/step - loss: 48.9323\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 0s 475us/step - loss: 48.5748\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 0s 479us/step - loss: 48.3570\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 0s 479us/step - loss: 49.3722\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 0s 496us/step - loss: 48.7898\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 0s 451us/step - loss: 48.4455\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 0s 426us/step - loss: 46.9092\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 0s 431us/step - loss: 46.7724\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 0s 483us/step - loss: 45.7877\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 47.1514\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 46.5347\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 45.7222\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 0s 326us/step - loss: 44.5079\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 44.4958\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 44.5791\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 44.1996\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 44.2133\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 45.0254\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 44.3173\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 43.1033\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 42.3423\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 43.5703\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 42.9882\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 42.1203\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 41.8713\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 43.5865\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 42.3211\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 41.8047\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 336us/step - loss: 42.5685\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 0s 317us/step - loss: 40.5900\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 0s 312us/step - loss: 41.5775\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 0s 307us/step - loss: 40.7539\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 0s 307us/step - loss: 40.7721\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 0s 306us/step - loss: 40.6483\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 0s 309us/step - loss: 39.7326\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 0s 309us/step - loss: 39.9828\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 0s 310us/step - loss: 39.9645\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 0s 307us/step - loss: 39.0487\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 0s 305us/step - loss: 39.4262\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 0s 307us/step - loss: 39.5628\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 0s 305us/step - loss: 40.0667\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 0s 310us/step - loss: 40.0663\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 0s 308us/step - loss: 38.4796\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 0s 316us/step - loss: 40.7547\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 0s 308us/step - loss: 39.1145\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 0s 307us/step - loss: 38.5302\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 0s 304us/step - loss: 38.5848\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 0s 311us/step - loss: 37.9784\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 0s 311us/step - loss: 39.0609\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 0s 307us/step - loss: 39.2595\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 0s 305us/step - loss: 38.3181\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 0s 305us/step - loss: 39.2978\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 0s 306us/step - loss: 37.5564\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 0s 304us/step - loss: 39.3078\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 0s 306us/step - loss: 37.1132\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 0s 307us/step - loss: 38.5449\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 0s 309us/step - loss: 39.4158\n",
      "33/33 [==============================] - 1s 20ms/step\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 164.3631\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 0s 301us/step - loss: 87.2727\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 69.4144\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 0s 478us/step - loss: 65.1004\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 0s 481us/step - loss: 63.0343\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 0s 404us/step - loss: 60.6300\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 0s 367us/step - loss: 58.0947\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 56.8111\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 0s 324us/step - loss: 55.1121\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 53.1381\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 51.9764\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 50.5096\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 49.4276\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 0s 326us/step - loss: 48.8504\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 48.3743\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 46.0216\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 44.6550\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 43.8731\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 42.5556\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 42.1446\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 39.5934\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 39.9106\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 39.8356\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 40.5260\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 0s 358us/step - loss: 42.9159\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 0s 423us/step - loss: 41.4368\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 0s 365us/step - loss: 40.3389\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 37.2612\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 37.2581\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 0s 396us/step - loss: 36.0469\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 0s 364us/step - loss: 37.7550\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 0s 375us/step - loss: 35.0552\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 0s 350us/step - loss: 35.4888\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 0s 381us/step - loss: 36.0788\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 34.1524\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 0s 326us/step - loss: 34.2186\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 0s 346us/step - loss: 33.7983\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 33.7257\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 0s 346us/step - loss: 34.8870\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 0s 344us/step - loss: 35.9616\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 0s 346us/step - loss: 38.1289\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 0s 346us/step - loss: 32.8687\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 32.7820\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 32.4882\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 32.4787\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 34.6555\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 32.2756\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 0s 324us/step - loss: 31.6693\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 33.1379\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 31.7443\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 32.2333\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 0s 326us/step - loss: 30.6904\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 32.3248\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 0s 325us/step - loss: 30.8456\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 31.6840\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 31.0976\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 31.06110s - loss: 33.36\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 0s 384us/step - loss: 30.4211\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 0s 381us/step - loss: 28.9980\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 0s 369us/step - loss: 30.4231\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 0s 368us/step - loss: 29.2627\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 0s 366us/step - loss: 28.8045\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 0s 375us/step - loss: 28.3761\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 0s 345us/step - loss: 29.6544\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 0s 350us/step - loss: 29.8663\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 412us/step - loss: 30.1167\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 0s 359us/step - loss: 29.2315\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 0s 355us/step - loss: 28.2558\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 0s 345us/step - loss: 27.6972\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 28.1498\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 0s 325us/step - loss: 27.1437\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 0s 318us/step - loss: 26.0175\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 26.2308\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 0s 372us/step - loss: 26.0406\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 0s 426us/step - loss: 26.3953\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 0s 345us/step - loss: 25.8598\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 0s 325us/step - loss: 27.2366\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 0s 318us/step - loss: 27.14260s - loss: 25.47\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 25.7822\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 0s 391us/step - loss: 25.3066\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 0s 383us/step - loss: 25.0952\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 0s 320us/step - loss: 24.2019\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 0s 316us/step - loss: 25.1824\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 24.8334\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 0s 345us/step - loss: 24.6433\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 25.0901\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 0s 325us/step - loss: 25.4939\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 0s 361us/step - loss: 24.6761\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 0s 350us/step - loss: 23.0029\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 0s 316us/step - loss: 24.1059\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 0s 320us/step - loss: 23.0437\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 0s 350us/step - loss: 22.4432\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 0s 358us/step - loss: 23.4749\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 24.5983\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 23.6528\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 0s 357us/step - loss: 22.5729\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 0s 376us/step - loss: 21.7782\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 0s 371us/step - loss: 22.1304\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 0s 343us/step - loss: 22.1303\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 0s 320us/step - loss: 23.0333\n",
      "33/33 [==============================] - 1s 20ms/step\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 369.5467\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 116.3406\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 0s 380us/step - loss: 102.1458\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 0s 757us/step - loss: 90.1829\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 0s 629us/step - loss: 84.2633\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 0s 515us/step - loss: 79.3074\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 0s 366us/step - loss: 74.3467\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 0s 443us/step - loss: 72.5550\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 68.1735\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 0s 314us/step - loss: 65.6024\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 0s 373us/step - loss: 62.4328\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 0s 531us/step - loss: 61.0651\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 0s 492us/step - loss: 60.8390\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 0s 493us/step - loss: 58.6597\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 0s 322us/step - loss: 58.5690\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 0s 323us/step - loss: 58.3453\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 56.1405\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 0s 322us/step - loss: 55.2629\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 54.1058\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 0s 384us/step - loss: 54.2350\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 0s 494us/step - loss: 52.1777\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 0s 373us/step - loss: 52.2792\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 51.2639\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 0s 304us/step - loss: 48.7466\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 48.1726\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 0s 408us/step - loss: 46.3986\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 0s 291us/step - loss: 46.5733\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 0s 282us/step - loss: 45.9421\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 0s 347us/step - loss: 44.6538\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 0s 483us/step - loss: 44.8668\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 0s 406us/step - loss: 42.5117\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 0s 313us/step - loss: 42.6293\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 41.0005\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 0s 377us/step - loss: 39.9942\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 0s 324us/step - loss: 40.1296\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 0s 492us/step - loss: 40.3884\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 0s 355us/step - loss: 38.0019\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 0s 360us/step - loss: 39.4486\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 40.1625\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 0s 377us/step - loss: 37.5436\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 38.1166\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 0s 478us/step - loss: 36.9683\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 0s 347us/step - loss: 35.8377\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 0s 344us/step - loss: 37.9906\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 0s 322us/step - loss: 37.6670\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 0s 375us/step - loss: 36.1280\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 0s 346us/step - loss: 37.2767\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 0s 315us/step - loss: 37.5840\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 0s 320us/step - loss: 33.9464\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 0s 298us/step - loss: 34.0916\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 0s 293us/step - loss: 34.5472\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 0s 297us/step - loss: 34.1290\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 0s 298us/step - loss: 33.7773\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 0s 429us/step - loss: 34.0513\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 0s 393us/step - loss: 34.8412\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 0s 353us/step - loss: 33.3688\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 31.9435\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 0s 319us/step - loss: 32.3728\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 0s 347us/step - loss: 32.0761\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 312us/step - loss: 33.8791\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 0s 322us/step - loss: 31.7610\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 0s 356us/step - loss: 32.1855\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 0s 308us/step - loss: 33.0011\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 0s 302us/step - loss: 31.3271\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 0s 287us/step - loss: 32.2143\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 0s 290us/step - loss: 32.2069\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 0s 280us/step - loss: 30.7111\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 0s 286us/step - loss: 31.0618\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 0s 303us/step - loss: 30.5340\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 0s 298us/step - loss: 30.5235\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 0s 279us/step - loss: 29.1510\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 0s 292us/step - loss: 30.0276\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 0s 291us/step - loss: 29.4244\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 0s 285us/step - loss: 31.3787\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 0s 285us/step - loss: 28.1347\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 0s 430us/step - loss: 28.5385\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 0s 372us/step - loss: 29.4266\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 0s 320us/step - loss: 29.4411\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 0s 285us/step - loss: 28.8848\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 0s 285us/step - loss: 27.8414\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 0s 368us/step - loss: 27.9247\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 0s 356us/step - loss: 28.8856\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 0s 303us/step - loss: 28.8265\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 0s 283us/step - loss: 27.5865\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 0s 291us/step - loss: 27.6357\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 26.9400\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 0s 309us/step - loss: 26.2552\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 0s 310us/step - loss: 26.7595\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 0s 295us/step - loss: 27.3639\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 0s 293us/step - loss: 26.5306\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 0s 323us/step - loss: 26.2557\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 0s 304us/step - loss: 27.2255\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 0s 290us/step - loss: 25.7625\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 0s 292us/step - loss: 26.0551\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 0s 290us/step - loss: 25.4111\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 0s 289us/step - loss: 24.5888\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 0s 287us/step - loss: 25.9198\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 0s 290us/step - loss: 25.1248\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 0s 291us/step - loss: 24.1521\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 0s 297us/step - loss: 24.0009\n",
      "33/33 [==============================] - 1s 20ms/step\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 387.3335\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 0s 301us/step - loss: 111.6431\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 87.7449\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 0s 300us/step - loss: 71.9235\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 0s 321us/step - loss: 61.3872\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 0s 312us/step - loss: 57.7258\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 0s 317us/step - loss: 55.4237\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 0s 292us/step - loss: 52.4546\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 0s 292us/step - loss: 52.3368\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 0s 315us/step - loss: 52.1672\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 0s 295us/step - loss: 50.4444\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 0s 294us/step - loss: 49.6382\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 0s 292us/step - loss: 49.0878\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 0s 319us/step - loss: 48.1595\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 0s 291us/step - loss: 47.7659\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 0s 294us/step - loss: 46.4322\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 0s 292us/step - loss: 45.6055\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 0s 293us/step - loss: 44.9291\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 0s 292us/step - loss: 44.5281\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 0s 291us/step - loss: 44.2406\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 0s 291us/step - loss: 43.5036\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 0s 295us/step - loss: 42.6237\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 0s 291us/step - loss: 41.6399\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 0s 293us/step - loss: 40.4716\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 0s 295us/step - loss: 41.5959\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 0s 301us/step - loss: 40.7656\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 0s 292us/step - loss: 39.3194\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 0s 290us/step - loss: 38.4898\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 0s 296us/step - loss: 38.1887\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 0s 293us/step - loss: 37.2978\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 0s 294us/step - loss: 37.3790\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 0s 289us/step - loss: 36.8917\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 0s 291us/step - loss: 36.5354\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 0s 305us/step - loss: 36.1127\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 0s 296us/step - loss: 35.5680\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 0s 298us/step - loss: 35.5325\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 0s 292us/step - loss: 34.6185\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 0s 295us/step - loss: 36.3613\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 0s 311us/step - loss: 33.7269\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 0s 354us/step - loss: 34.2613\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 33.7873\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 0s 320us/step - loss: 32.3150\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 0s 312us/step - loss: 32.7646\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 0s 289us/step - loss: 32.3873\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 0s 346us/step - loss: 32.7810\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 0s 318us/step - loss: 33.1861\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 0s 357us/step - loss: 31.8356\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 32.1565\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 31.9029\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 31.38020s - loss: 34.61\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 32.1020\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 0s 308us/step - loss: 31.4258\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 0s 316us/step - loss: 30.6442\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 296us/step - loss: 31.4565\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 0s 286us/step - loss: 30.3703\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 0s 298us/step - loss: 30.2961\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 0s 409us/step - loss: 30.0723\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 0s 399us/step - loss: 29.9951\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 0s 320us/step - loss: 30.4764\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 0s 320us/step - loss: 30.2960\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 0s 369us/step - loss: 30.1879\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 30.0629\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 30.0868\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 29.3768\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 0s 302us/step - loss: 29.4439\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 0s 295us/step - loss: 29.7409\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 0s 311us/step - loss: 28.6107\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 0s 298us/step - loss: 30.3138\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 0s 408us/step - loss: 29.0341\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 0s 315us/step - loss: 28.9638\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 28.9492\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 0s 306us/step - loss: 28.8239\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 28.8170\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 0s 359us/step - loss: 28.5633\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 0s 326us/step - loss: 29.4203\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 0s 462us/step - loss: 27.9528\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 0s 384us/step - loss: 29.6246\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 28.7784\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 0s 324us/step - loss: 28.2828\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 0s 496us/step - loss: 28.06760s - loss: 27.\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 0s 384us/step - loss: 28.0558\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 28.8464\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 0s 375us/step - loss: 27.8303\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 0s 362us/step - loss: 27.8960\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 0s 368us/step - loss: 28.0391\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 26.7103\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 0s 541us/step - loss: 27.2456\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 0s 442us/step - loss: 28.0614\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 0s 384us/step - loss: 28.3551\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 27.4429\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 0s 317us/step - loss: 28.0448\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 26.9855\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 0s 497us/step - loss: 27.1286\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 0s 417us/step - loss: 29.0421\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 0s 435us/step - loss: 26.9361\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 26.6692\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 0s 353us/step - loss: 26.7759\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 0s 366us/step - loss: 26.7648\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 0s 375us/step - loss: 26.3642\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 0s 397us/step - loss: 26.4729\n",
      "33/33 [==============================] - 1s 21ms/step\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 287.1762\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 0s 365us/step - loss: 100.1681\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 0s 366us/step - loss: 88.4402\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 0s 366us/step - loss: 76.8370\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 0s 377us/step - loss: 71.3346\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 69.8625\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 67.0405\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 0s 326us/step - loss: 65.1170\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 0s 323us/step - loss: 65.5340\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 62.4353\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 60.2729\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 0s 314us/step - loss: 59.0956\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 59.3797\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 0s 321us/step - loss: 56.1204\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 53.1894\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 52.4426\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 0s 320us/step - loss: 51.0189\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 0s 374us/step - loss: 49.0449\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 0s 318us/step - loss: 48.7804\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 47.5889\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 46.8772\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 0s 316us/step - loss: 43.7537\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 0s 317us/step - loss: 42.7818\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 0s 357us/step - loss: 44.4510\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 0s 318us/step - loss: 47.4022\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 0s 312us/step - loss: 44.2044\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 0s 310us/step - loss: 40.3993\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 39.7599\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 0s 317us/step - loss: 39.6261\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 0s 316us/step - loss: 39.4555\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 38.3718\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 0s 355us/step - loss: 40.4440\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 0s 321us/step - loss: 39.9010\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 36.2207\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 0s 345us/step - loss: 37.2502\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 0s 384us/step - loss: 37.1397\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 0s 354us/step - loss: 36.3478\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 0s 358us/step - loss: 36.9382\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 35.5037\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 37.9645\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 0s 319us/step - loss: 36.2843\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 0s 309us/step - loss: 36.2500\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 0s 347us/step - loss: 35.7270\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 0s 343us/step - loss: 34.2576\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 34.7751\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 0s 316us/step - loss: 33.8227\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 0s 400us/step - loss: 34.1269\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 380us/step - loss: 34.7731\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 0s 356us/step - loss: 34.2277\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 34.7012\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 33.2121\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 0s 313us/step - loss: 38.1272\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 33.2232\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 0s 374us/step - loss: 33.8301\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 0s 321us/step - loss: 32.4110\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 0s 316us/step - loss: 32.8453\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 0s 310us/step - loss: 32.7096\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 32.6446\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 0s 311us/step - loss: 32.6752\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 0s 351us/step - loss: 32.0545\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 0s 348us/step - loss: 33.1550\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 30.7275\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 0s 312us/step - loss: 31.1608\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 32.7567\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 0s 307us/step - loss: 31.2690\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 32.7242\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 0s 306us/step - loss: 32.2450\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 0s 310us/step - loss: 31.9418\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 0s 416us/step - loss: 30.2145\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 0s 318us/step - loss: 30.6949\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 0s 311us/step - loss: 29.5794\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 29.8795\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 0s 367us/step - loss: 29.9556\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 0s 389us/step - loss: 29.7115\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 0s 418us/step - loss: 28.8488\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 0s 347us/step - loss: 30.9127\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 0s 343us/step - loss: 29.0270\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 0s 372us/step - loss: 28.5017\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 0s 317us/step - loss: 27.9086\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 0s 346us/step - loss: 27.7580\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 0s 323us/step - loss: 29.3285\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 0s 311us/step - loss: 28.9364\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 0s 367us/step - loss: 29.0470\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 0s 322us/step - loss: 27.7062\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 0s 349us/step - loss: 26.7880\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 0s 384us/step - loss: 26.9437\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 0s 324us/step - loss: 27.3559\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 0s 360us/step - loss: 26.7137\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 0s 369us/step - loss: 25.7972\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 0s 365us/step - loss: 25.8962\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 0s 362us/step - loss: 25.7638\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 0s 326us/step - loss: 26.9361\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 0s 379us/step - loss: 25.8515\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 0s 314us/step - loss: 25.2580\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 25.0526\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 0s 307us/step - loss: 26.3806\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 0s 344us/step - loss: 26.5340\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 0s 318us/step - loss: 24.5485\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 0s 315us/step - loss: 24.9190\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 0s 324us/step - loss: 30.0420\n",
      "33/33 [==============================] - 1s 21ms/step\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 198.3068\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 0s 325us/step - loss: 104.2904\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 0s 320us/step - loss: 81.6863\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 75.5348\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 71.8919\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 0s 345us/step - loss: 70.1657\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 0s 325us/step - loss: 66.9427\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 0s 321us/step - loss: 66.9609\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 0s 385us/step - loss: 63.4760\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 0s 349us/step - loss: 63.8451\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 0s 351us/step - loss: 61.6109\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 0s 386us/step - loss: 61.3891\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 0s 344us/step - loss: 58.5757\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 0s 321us/step - loss: 60.0117\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 0s 434us/step - loss: 57.7620\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 55.4579\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 0s 394us/step - loss: 53.8649\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 0s 418us/step - loss: 51.9112\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 0s 407us/step - loss: 52.2766\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 0s 382us/step - loss: 50.0447\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 0s 388us/step - loss: 48.4887\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 0s 306us/step - loss: 50.1918\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 46.2578\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 0s 384us/step - loss: 45.6342\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 44.2498\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 45.8052\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 0s 390us/step - loss: 43.6391\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 0s 377us/step - loss: 42.5586\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 42.5150\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 41.9507\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 0s 366us/step - loss: 42.4126\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 40.2542\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 0s 343us/step - loss: 41.5009\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 0s 319us/step - loss: 39.2550\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 0s 372us/step - loss: 40.6138\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 0s 371us/step - loss: 38.6140\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 0s 344us/step - loss: 38.6916\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 0s 377us/step - loss: 37.7173\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 43.4482\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 0s 384us/step - loss: 41.3918\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 0s 368us/step - loss: 38.6449\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 374us/step - loss: 40.0166\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 38.8716\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 0s 349us/step - loss: 37.9521\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 0s 357us/step - loss: 37.1415\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 0s 346us/step - loss: 37.2094\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 0s 373us/step - loss: 37.6395\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 38.4766\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 0s 345us/step - loss: 37.4912\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 37.0056\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 0s 348us/step - loss: 35.9378\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 0s 321us/step - loss: 40.0252\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 37.7484\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 0s 325us/step - loss: 36.3676\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 35.8007\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 36.1867\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 0s 321us/step - loss: 35.5816\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 35.7538\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 0s 323us/step - loss: 35.8081\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 37.1913\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 0s 303us/step - loss: 35.6844\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 36.7215\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 37.8854\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 0s 346us/step - loss: 37.2951\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 37.9303\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 34.5341\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 43.11 - 0s 339us/step - loss: 34.8455\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 0s 345us/step - loss: 34.9074\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 35.1482\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 36.4113\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 35.7870\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 0s 318us/step - loss: 34.8515\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 0s 298us/step - loss: 34.4855\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 0s 296us/step - loss: 35.3548\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 0s 290us/step - loss: 35.1060\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 0s 367us/step - loss: 35.3164\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 0s 380us/step - loss: 34.4609\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 0s 308us/step - loss: 33.9909\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 0s 297us/step - loss: 34.4021\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 0s 348us/step - loss: 34.0127\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 0s 326us/step - loss: 34.3629\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 0s 356us/step - loss: 33.3376\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 0s 360us/step - loss: 33.4398\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 0s 311us/step - loss: 32.8010\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 0s 292us/step - loss: 35.2374\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 0s 292us/step - loss: 34.4710\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 34.0494\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 33.3487\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 0s 344us/step - loss: 32.7235\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 32.3665\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 0s 317us/step - loss: 32.5492\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 0s 354us/step - loss: 32.4948\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 36.0761\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 0s 354us/step - loss: 33.7860\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 0s 351us/step - loss: 31.1211\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 0s 322us/step - loss: 31.0862\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 0s 348us/step - loss: 32.4357\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 0s 311us/step - loss: 31.5165\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 0s 313us/step - loss: 32.7053\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 0s 326us/step - loss: 31.8589\n",
      "33/33 [==============================] - 1s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, X, y, cv=kfold) # this here does not fit the data. The training is not remembered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-14.94179775, -14.17593692, -16.84863106, -58.7879664 ,\n",
       "       -83.97174049, -26.38940849, -20.7661606 , -93.84333129,\n",
       "       -21.6596203 , -34.2726502 ])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-38.5657243492769"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.142808960895973"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This explains the negative Mean Squared Error score. Negative is ok. Just take the absolute number.\n",
    "<img src='mse_negative.png' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second model that standardizes the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "3  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "4  0.08829  12.5   7.87     0  0.524  6.012  66.6  5.5605    5  311     15.2   \n",
       "\n",
       "    black  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  394.63   2.94  33.4  \n",
       "3  396.90   5.33  36.2  \n",
       "4  395.60  12.43  22.9  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "# As you can see that the values among the features are quite varied. The range of some is less than one - \n",
    "# Some in the tense and some in the hundreads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "299/299 [==============================] - 2s 6ms/step - loss: 612.1286\n",
      "Epoch 2/100\n",
      "299/299 [==============================] - 0s 329us/step - loss: 592.6153\n",
      "Epoch 3/100\n",
      "299/299 [==============================] - 0s 329us/step - loss: 550.3283\n",
      "Epoch 4/100\n",
      "299/299 [==============================] - 0s 331us/step - loss: 484.2721\n",
      "Epoch 5/100\n",
      "299/299 [==============================] - 0s 332us/step - loss: 403.1776\n",
      "Epoch 6/100\n",
      "299/299 [==============================] - 0s 331us/step - loss: 320.2773\n",
      "Epoch 7/100\n",
      "299/299 [==============================] - 0s 336us/step - loss: 246.2449\n",
      "Epoch 8/100\n",
      "299/299 [==============================] - 0s 332us/step - loss: 187.3916\n",
      "Epoch 9/100\n",
      "299/299 [==============================] - 0s 328us/step - loss: 144.4475\n",
      "Epoch 10/100\n",
      "299/299 [==============================] - 0s 336us/step - loss: 114.5476\n",
      "Epoch 11/100\n",
      "299/299 [==============================] - 0s 367us/step - loss: 93.5855\n",
      "Epoch 12/100\n",
      "299/299 [==============================] - 0s 344us/step - loss: 78.6990\n",
      "Epoch 13/100\n",
      "299/299 [==============================] - 0s 331us/step - loss: 67.5156\n",
      "Epoch 14/100\n",
      "299/299 [==============================] - 0s 332us/step - loss: 59.0210\n",
      "Epoch 15/100\n",
      "299/299 [==============================] - 0s 332us/step - loss: 52.6044\n",
      "Epoch 16/100\n",
      "299/299 [==============================] - 0s 332us/step - loss: 47.7767\n",
      "Epoch 17/100\n",
      "299/299 [==============================] - 0s 333us/step - loss: 44.2610\n",
      "Epoch 18/100\n",
      "299/299 [==============================] - 0s 331us/step - loss: 41.3330\n",
      "Epoch 19/100\n",
      "299/299 [==============================] - 0s 333us/step - loss: 39.1569\n",
      "Epoch 20/100\n",
      "299/299 [==============================] - 0s 338us/step - loss: 37.2642\n",
      "Epoch 21/100\n",
      "299/299 [==============================] - 0s 332us/step - loss: 35.6966\n",
      "Epoch 22/100\n",
      "299/299 [==============================] - 0s 331us/step - loss: 34.3878\n",
      "Epoch 23/100\n",
      "299/299 [==============================] - 0s 329us/step - loss: 33.2652\n",
      "Epoch 24/100\n",
      "299/299 [==============================] - 0s 338us/step - loss: 32.3174\n",
      "Epoch 25/100\n",
      "299/299 [==============================] - 0s 369us/step - loss: 31.4542\n",
      "Epoch 26/100\n",
      "299/299 [==============================] - 0s 348us/step - loss: 30.6531\n",
      "Epoch 27/100\n",
      "299/299 [==============================] - 0s 509us/step - loss: 29.9694\n",
      "Epoch 28/100\n",
      "299/299 [==============================] - 0s 470us/step - loss: 29.2212\n",
      "Epoch 29/100\n",
      "299/299 [==============================] - 0s 457us/step - loss: 28.5851\n",
      "Epoch 30/100\n",
      "299/299 [==============================] - 0s 381us/step - loss: 28.0564\n",
      "Epoch 31/100\n",
      "299/299 [==============================] - 0s 452us/step - loss: 27.5038\n",
      "Epoch 32/100\n",
      "299/299 [==============================] - 0s 339us/step - loss: 27.0222\n",
      "Epoch 33/100\n",
      "299/299 [==============================] - 0s 336us/step - loss: 26.5713\n",
      "Epoch 34/100\n",
      "299/299 [==============================] - 0s 430us/step - loss: 26.1070\n",
      "Epoch 35/100\n",
      "299/299 [==============================] - 0s 478us/step - loss: 25.7282\n",
      "Epoch 36/100\n",
      "299/299 [==============================] - 0s 423us/step - loss: 25.2816\n",
      "Epoch 37/100\n",
      "299/299 [==============================] - 0s 488us/step - loss: 24.9472\n",
      "Epoch 38/100\n",
      "299/299 [==============================] - 0s 412us/step - loss: 24.5961\n",
      "Epoch 39/100\n",
      "299/299 [==============================] - 0s 346us/step - loss: 24.3145\n",
      "Epoch 40/100\n",
      "299/299 [==============================] - 0s 335us/step - loss: 24.0885\n",
      "Epoch 41/100\n",
      "299/299 [==============================] - 0s 339us/step - loss: 23.6816\n",
      "Epoch 42/100\n",
      "299/299 [==============================] - 0s 335us/step - loss: 23.4009\n",
      "Epoch 43/100\n",
      "299/299 [==============================] - 0s 331us/step - loss: 23.2121\n",
      "Epoch 44/100\n",
      "299/299 [==============================] - 0s 338us/step - loss: 22.9172\n",
      "Epoch 45/100\n",
      "299/299 [==============================] - 0s 325us/step - loss: 22.6318\n",
      "Epoch 46/100\n",
      "299/299 [==============================] - 0s 337us/step - loss: 22.4411\n",
      "Epoch 47/100\n",
      "299/299 [==============================] - 0s 330us/step - loss: 22.1706\n",
      "Epoch 48/100\n",
      "299/299 [==============================] - 0s 331us/step - loss: 21.9683\n",
      "Epoch 49/100\n",
      "299/299 [==============================] - 0s 360us/step - loss: 21.8655\n",
      "Epoch 50/100\n",
      "299/299 [==============================] - 0s 393us/step - loss: 21.6323\n",
      "Epoch 51/100\n",
      "299/299 [==============================] - 0s 349us/step - loss: 21.4665\n",
      "Epoch 52/100\n",
      "299/299 [==============================] - 0s 330us/step - loss: 21.2179\n",
      "Epoch 53/100\n",
      "299/299 [==============================] - 0s 339us/step - loss: 20.9291\n",
      "Epoch 54/100\n",
      "299/299 [==============================] - 0s 329us/step - loss: 20.8234\n",
      "Epoch 55/100\n",
      "299/299 [==============================] - 0s 337us/step - loss: 20.6814\n",
      "Epoch 56/100\n",
      "299/299 [==============================] - 0s 339us/step - loss: 20.4359\n",
      "Epoch 57/100\n",
      "299/299 [==============================] - 0s 334us/step - loss: 20.2735\n",
      "Epoch 58/100\n",
      "299/299 [==============================] - 0s 391us/step - loss: 20.1352\n",
      "Epoch 59/100\n",
      "299/299 [==============================] - 0s 335us/step - loss: 20.0086\n",
      "Epoch 60/100\n",
      "299/299 [==============================] - 0s 359us/step - loss: 19.8017\n",
      "Epoch 61/100\n",
      "299/299 [==============================] - 0s 409us/step - loss: 19.6556\n",
      "Epoch 62/100\n",
      "299/299 [==============================] - 0s 325us/step - loss: 19.5436\n",
      "Epoch 63/100\n",
      "299/299 [==============================] - 0s 330us/step - loss: 19.3919\n",
      "Epoch 64/100\n",
      "299/299 [==============================] - 0s 345us/step - loss: 19.2864\n",
      "Epoch 65/100\n",
      "299/299 [==============================] - 0s 403us/step - loss: 19.2492\n",
      "Epoch 66/100\n",
      "299/299 [==============================] - 0s 346us/step - loss: 18.9400\n",
      "Epoch 67/100\n",
      "299/299 [==============================] - 0s 330us/step - loss: 18.8548\n",
      "Epoch 68/100\n",
      "299/299 [==============================] - 0s 354us/step - loss: 18.7218\n",
      "Epoch 69/100\n",
      "299/299 [==============================] - 0s 480us/step - loss: 18.6076\n",
      "Epoch 70/100\n",
      "299/299 [==============================] - 0s 424us/step - loss: 18.4148\n",
      "Epoch 71/100\n",
      "299/299 [==============================] - 0s 433us/step - loss: 18.2800\n",
      "Epoch 72/100\n",
      "299/299 [==============================] - 0s 409us/step - loss: 18.1142\n",
      "Epoch 73/100\n",
      "299/299 [==============================] - 0s 414us/step - loss: 18.0427\n",
      "Epoch 74/100\n",
      "299/299 [==============================] - 0s 398us/step - loss: 17.8894\n",
      "Epoch 75/100\n",
      "299/299 [==============================] - 0s 411us/step - loss: 17.7824\n",
      "Epoch 76/100\n",
      "299/299 [==============================] - 0s 452us/step - loss: 17.6510\n",
      "Epoch 77/100\n",
      "299/299 [==============================] - 0s 382us/step - loss: 17.5905\n",
      "Epoch 78/100\n",
      "299/299 [==============================] - 0s 343us/step - loss: 17.3985\n",
      "Epoch 79/100\n",
      "299/299 [==============================] - 0s 333us/step - loss: 17.3674\n",
      "Epoch 80/100\n",
      "299/299 [==============================] - 0s 347us/step - loss: 17.2558\n",
      "Epoch 81/100\n",
      "299/299 [==============================] - 0s 477us/step - loss: 17.1205\n",
      "Epoch 82/100\n",
      "299/299 [==============================] - 0s 447us/step - loss: 16.96740s - loss: 16.\n",
      "Epoch 83/100\n",
      "299/299 [==============================] - 0s 387us/step - loss: 16.9102\n",
      "Epoch 84/100\n",
      "299/299 [==============================] - 0s 403us/step - loss: 16.9000\n",
      "Epoch 85/100\n",
      "299/299 [==============================] - 0s 378us/step - loss: 16.6255\n",
      "Epoch 86/100\n",
      "299/299 [==============================] - 0s 343us/step - loss: 16.5969\n",
      "Epoch 87/100\n",
      "299/299 [==============================] - 0s 334us/step - loss: 16.5192\n",
      "Epoch 88/100\n",
      "299/299 [==============================] - 0s 537us/step - loss: 16.4033\n",
      "Epoch 89/100\n",
      "299/299 [==============================] - 0s 480us/step - loss: 16.2603\n",
      "Epoch 90/100\n",
      "299/299 [==============================] - 0s 509us/step - loss: 16.1636\n",
      "Epoch 91/100\n",
      "299/299 [==============================] - 0s 494us/step - loss: 16.0443\n",
      "Epoch 92/100\n",
      "299/299 [==============================] - 0s 509us/step - loss: 16.0206\n",
      "Epoch 93/100\n",
      "299/299 [==============================] - 0s 483us/step - loss: 15.7973\n",
      "Epoch 94/100\n",
      "299/299 [==============================] - 0s 440us/step - loss: 15.7182\n",
      "Epoch 95/100\n",
      "299/299 [==============================] - 0s 506us/step - loss: 15.5832\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 0s 515us/step - loss: 15.5855\n",
      "Epoch 97/100\n",
      "299/299 [==============================] - 0s 519us/step - loss: 15.4216\n",
      "Epoch 98/100\n",
      "299/299 [==============================] - 0s 386us/step - loss: 15.3504\n",
      "Epoch 99/100\n",
      "299/299 [==============================] - 0s 374us/step - loss: 15.2406\n",
      "Epoch 100/100\n",
      "299/299 [==============================] - 0s 510us/step - loss: 15.1770\n",
      "34/34 [==============================] - 1s 20ms/step\n",
      "Epoch 1/100\n",
      "299/299 [==============================] - 2s 7ms/step - loss: 599.4115\n",
      "Epoch 2/100\n",
      "299/299 [==============================] - 0s 325us/step - loss: 581.0918\n",
      "Epoch 3/100\n",
      "299/299 [==============================] - 0s 316us/step - loss: 546.9340\n",
      "Epoch 4/100\n",
      "299/299 [==============================] - 0s 319us/step - loss: 497.4099\n",
      "Epoch 5/100\n",
      "299/299 [==============================] - 0s 320us/step - loss: 438.3853\n",
      "Epoch 6/100\n",
      "299/299 [==============================] - 0s 316us/step - loss: 375.4113\n",
      "Epoch 7/100\n",
      "299/299 [==============================] - 0s 324us/step - loss: 313.9773\n",
      "Epoch 8/100\n",
      "299/299 [==============================] - 0s 372us/step - loss: 256.5262\n",
      "Epoch 9/100\n",
      "299/299 [==============================] - 0s 330us/step - loss: 204.6962\n",
      "Epoch 10/100\n",
      "299/299 [==============================] - 0s 331us/step - loss: 158.6819\n",
      "Epoch 11/100\n",
      "299/299 [==============================] - 0s 464us/step - loss: 120.3144\n",
      "Epoch 12/100\n",
      "299/299 [==============================] - 0s 400us/step - loss: 88.7992\n",
      "Epoch 13/100\n",
      "299/299 [==============================] - 0s 348us/step - loss: 65.7345\n",
      "Epoch 14/100\n",
      "299/299 [==============================] - 0s 324us/step - loss: 51.5057\n",
      "Epoch 15/100\n",
      "299/299 [==============================] - 0s 468us/step - loss: 43.5120\n",
      "Epoch 16/100\n",
      "299/299 [==============================] - 0s 424us/step - loss: 38.7493\n",
      "Epoch 17/100\n",
      "299/299 [==============================] - 0s 388us/step - loss: 35.6530\n",
      "Epoch 18/100\n",
      "299/299 [==============================] - 0s 389us/step - loss: 33.4907\n",
      "Epoch 19/100\n",
      "299/299 [==============================] - 0s 377us/step - loss: 31.9248\n",
      "Epoch 20/100\n",
      "299/299 [==============================] - 0s 380us/step - loss: 30.6133\n",
      "Epoch 21/100\n",
      "299/299 [==============================] - 0s 408us/step - loss: 29.4589\n",
      "Epoch 22/100\n",
      "299/299 [==============================] - 0s 440us/step - loss: 28.5243\n",
      "Epoch 23/100\n",
      "299/299 [==============================] - 0s 444us/step - loss: 27.7971\n",
      "Epoch 24/100\n",
      "299/299 [==============================] - 0s 341us/step - loss: 27.0593\n",
      "Epoch 25/100\n",
      "299/299 [==============================] - 0s 345us/step - loss: 26.4409\n",
      "Epoch 26/100\n",
      "299/299 [==============================] - 0s 453us/step - loss: 25.8697\n",
      "Epoch 27/100\n",
      "299/299 [==============================] - 0s 448us/step - loss: 25.3323\n",
      "Epoch 28/100\n",
      "299/299 [==============================] - 0s 532us/step - loss: 24.9406\n",
      "Epoch 29/100\n",
      "299/299 [==============================] - 0s 349us/step - loss: 24.5876\n",
      "Epoch 30/100\n",
      "299/299 [==============================] - 0s 321us/step - loss: 24.2392\n",
      "Epoch 31/100\n",
      "299/299 [==============================] - 0s 405us/step - loss: 23.7978\n",
      "Epoch 32/100\n",
      "299/299 [==============================] - 0s 391us/step - loss: 23.4172\n",
      "Epoch 33/100\n",
      "299/299 [==============================] - 0s 337us/step - loss: 23.1601\n",
      "Epoch 34/100\n",
      "299/299 [==============================] - 0s 331us/step - loss: 22.8287\n",
      "Epoch 35/100\n",
      "299/299 [==============================] - 0s 327us/step - loss: 22.5341\n",
      "Epoch 36/100\n",
      "299/299 [==============================] - 0s 334us/step - loss: 22.3371\n",
      "Epoch 37/100\n",
      "299/299 [==============================] - 0s 334us/step - loss: 22.1198\n",
      "Epoch 38/100\n",
      "299/299 [==============================] - 0s 325us/step - loss: 21.8067\n",
      "Epoch 39/100\n",
      "299/299 [==============================] - 0s 328us/step - loss: 21.6069\n",
      "Epoch 40/100\n",
      "299/299 [==============================] - 0s 330us/step - loss: 21.3401\n",
      "Epoch 41/100\n",
      "299/299 [==============================] - 0s 335us/step - loss: 21.1266\n",
      "Epoch 42/100\n",
      "299/299 [==============================] - 0s 333us/step - loss: 20.8352\n",
      "Epoch 43/100\n",
      "299/299 [==============================] - 0s 335us/step - loss: 20.6809\n",
      "Epoch 44/100\n",
      "299/299 [==============================] - 0s 327us/step - loss: 20.3927\n",
      "Epoch 45/100\n",
      "299/299 [==============================] - 0s 328us/step - loss: 20.1983\n",
      "Epoch 46/100\n",
      "299/299 [==============================] - 0s 326us/step - loss: 19.9885\n",
      "Epoch 47/100\n",
      "299/299 [==============================] - 0s 323us/step - loss: 19.7565\n",
      "Epoch 48/100\n",
      "299/299 [==============================] - 0s 336us/step - loss: 19.5047\n",
      "Epoch 49/100\n",
      "299/299 [==============================] - 0s 330us/step - loss: 19.3448\n",
      "Epoch 50/100\n",
      "299/299 [==============================] - 0s 334us/step - loss: 19.1001\n",
      "Epoch 51/100\n",
      "299/299 [==============================] - 0s 339us/step - loss: 18.8437\n",
      "Epoch 52/100\n",
      "299/299 [==============================] - 0s 330us/step - loss: 18.7252\n",
      "Epoch 53/100\n",
      "299/299 [==============================] - 0s 329us/step - loss: 18.5119\n",
      "Epoch 54/100\n",
      "299/299 [==============================] - 0s 331us/step - loss: 18.3164\n",
      "Epoch 55/100\n",
      "299/299 [==============================] - 0s 330us/step - loss: 18.1102\n",
      "Epoch 56/100\n",
      "299/299 [==============================] - 0s 344us/step - loss: 17.8562\n",
      "Epoch 57/100\n",
      "299/299 [==============================] - 0s 321us/step - loss: 17.6274\n",
      "Epoch 58/100\n",
      "299/299 [==============================] - 0s 338us/step - loss: 17.4989\n",
      "Epoch 59/100\n",
      "299/299 [==============================] - 0s 378us/step - loss: 17.2523\n",
      "Epoch 60/100\n",
      "299/299 [==============================] - 0s 335us/step - loss: 17.1409\n",
      "Epoch 61/100\n",
      "299/299 [==============================] - 0s 385us/step - loss: 16.9433\n",
      "Epoch 62/100\n",
      "299/299 [==============================] - 0s 450us/step - loss: 16.7325\n",
      "Epoch 63/100\n",
      "299/299 [==============================] - 0s 352us/step - loss: 16.6763\n",
      "Epoch 64/100\n",
      "299/299 [==============================] - 0s 318us/step - loss: 16.4417\n",
      "Epoch 65/100\n",
      "299/299 [==============================] - 0s 334us/step - loss: 16.2608\n",
      "Epoch 66/100\n",
      "299/299 [==============================] - 0s 380us/step - loss: 16.1041\n",
      "Epoch 67/100\n",
      "299/299 [==============================] - 0s 340us/step - loss: 15.9399\n",
      "Epoch 68/100\n",
      "299/299 [==============================] - 0s 380us/step - loss: 15.8590\n",
      "Epoch 69/100\n",
      "299/299 [==============================] - 0s 325us/step - loss: 15.6319\n",
      "Epoch 70/100\n",
      "299/299 [==============================] - 0s 324us/step - loss: 15.5157\n",
      "Epoch 71/100\n",
      "299/299 [==============================] - 0s 322us/step - loss: 15.3104\n",
      "Epoch 72/100\n",
      "299/299 [==============================] - 0s 320us/step - loss: 15.1958\n",
      "Epoch 73/100\n",
      "299/299 [==============================] - 0s 334us/step - loss: 15.0889\n",
      "Epoch 74/100\n",
      "299/299 [==============================] - 0s 322us/step - loss: 14.8936\n",
      "Epoch 75/100\n",
      "299/299 [==============================] - 0s 322us/step - loss: 14.7252\n",
      "Epoch 76/100\n",
      "299/299 [==============================] - 0s 326us/step - loss: 14.6280\n",
      "Epoch 77/100\n",
      "299/299 [==============================] - 0s 369us/step - loss: 14.5358\n",
      "Epoch 78/100\n",
      "299/299 [==============================] - 0s 331us/step - loss: 14.3435\n",
      "Epoch 79/100\n",
      "299/299 [==============================] - 0s 330us/step - loss: 14.2452\n",
      "Epoch 80/100\n",
      "299/299 [==============================] - 0s 326us/step - loss: 14.0760\n",
      "Epoch 81/100\n",
      "299/299 [==============================] - 0s 334us/step - loss: 14.0036\n",
      "Epoch 82/100\n",
      "299/299 [==============================] - 0s 331us/step - loss: 13.8452\n",
      "Epoch 83/100\n",
      "299/299 [==============================] - 0s 324us/step - loss: 13.7370\n",
      "Epoch 84/100\n",
      "299/299 [==============================] - 0s 329us/step - loss: 13.6338\n",
      "Epoch 85/100\n",
      "299/299 [==============================] - 0s 333us/step - loss: 13.5616\n",
      "Epoch 86/100\n",
      "299/299 [==============================] - 0s 345us/step - loss: 13.4627\n",
      "Epoch 87/100\n",
      "299/299 [==============================] - 0s 331us/step - loss: 13.3074\n",
      "Epoch 88/100\n",
      "299/299 [==============================] - 0s 333us/step - loss: 13.2608\n",
      "Epoch 89/100\n",
      "299/299 [==============================] - 0s 324us/step - loss: 13.1113\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 0s 326us/step - loss: 13.0127\n",
      "Epoch 91/100\n",
      "299/299 [==============================] - 0s 335us/step - loss: 12.8756\n",
      "Epoch 92/100\n",
      "299/299 [==============================] - 0s 321us/step - loss: 12.8489\n",
      "Epoch 93/100\n",
      "299/299 [==============================] - 0s 341us/step - loss: 12.7989\n",
      "Epoch 94/100\n",
      "299/299 [==============================] - 0s 334us/step - loss: 12.7112\n",
      "Epoch 95/100\n",
      "299/299 [==============================] - 0s 327us/step - loss: 12.5724\n",
      "Epoch 96/100\n",
      "299/299 [==============================] - 0s 323us/step - loss: 12.4802\n",
      "Epoch 97/100\n",
      "299/299 [==============================] - 0s 319us/step - loss: 12.3828\n",
      "Epoch 98/100\n",
      "299/299 [==============================] - 0s 320us/step - loss: 12.3152\n",
      "Epoch 99/100\n",
      "299/299 [==============================] - 0s 329us/step - loss: 12.2819\n",
      "Epoch 100/100\n",
      "299/299 [==============================] - 0s 327us/step - loss: 12.1338\n",
      "34/34 [==============================] - 1s 21ms/step\n",
      "Epoch 1/100\n",
      "299/299 [==============================] - 2s 6ms/step - loss: 628.1064\n",
      "Epoch 2/100\n",
      "299/299 [==============================] - 0s 379us/step - loss: 610.9013\n",
      "Epoch 3/100\n",
      "299/299 [==============================] - 0s 378us/step - loss: 575.2880\n",
      "Epoch 4/100\n",
      "299/299 [==============================] - 0s 399us/step - loss: 520.6867\n",
      "Epoch 5/100\n",
      "299/299 [==============================] - 0s 345us/step - loss: 447.3063\n",
      "Epoch 6/100\n",
      "299/299 [==============================] - 0s 323us/step - loss: 361.9595\n",
      "Epoch 7/100\n",
      "299/299 [==============================] - 0s 377us/step - loss: 269.8214\n",
      "Epoch 8/100\n",
      "299/299 [==============================] - 0s 377us/step - loss: 192.0634\n",
      "Epoch 9/100\n",
      "299/299 [==============================] - 0s 347us/step - loss: 137.0451\n",
      "Epoch 10/100\n",
      "299/299 [==============================] - 0s 328us/step - loss: 102.7931\n",
      "Epoch 11/100\n",
      "299/299 [==============================] - 0s 356us/step - loss: 81.4375\n",
      "Epoch 12/100\n",
      "299/299 [==============================] - 0s 357us/step - loss: 68.0137\n",
      "Epoch 13/100\n",
      "299/299 [==============================] - 0s 350us/step - loss: 58.2754\n",
      "Epoch 14/100\n",
      "299/299 [==============================] - 0s 341us/step - loss: 51.4386\n",
      "Epoch 15/100\n",
      "299/299 [==============================] - 0s 344us/step - loss: 46.0302\n",
      "Epoch 16/100\n",
      "299/299 [==============================] - 0s 341us/step - loss: 42.0778\n",
      "Epoch 17/100\n",
      "299/299 [==============================] - 0s 368us/step - loss: 39.1823\n",
      "Epoch 18/100\n",
      "299/299 [==============================] - 0s 406us/step - loss: 37.0813\n",
      "Epoch 19/100\n",
      "299/299 [==============================] - 0s 375us/step - loss: 35.4639\n",
      "Epoch 20/100\n",
      "299/299 [==============================] - 0s 358us/step - loss: 34.1430\n",
      "Epoch 21/100\n",
      "299/299 [==============================] - 0s 377us/step - loss: 33.1905\n",
      "Epoch 22/100\n",
      "299/299 [==============================] - 0s 388us/step - loss: 32.4434\n",
      "Epoch 23/100\n",
      "299/299 [==============================] - 0s 404us/step - loss: 31.6861\n",
      "Epoch 24/100\n",
      "299/299 [==============================] - 0s 341us/step - loss: 31.1078\n",
      "Epoch 25/100\n",
      "299/299 [==============================] - 0s 340us/step - loss: 30.6202\n",
      "Epoch 26/100\n",
      "299/299 [==============================] - 0s 355us/step - loss: 30.0827\n",
      "Epoch 27/100\n",
      "299/299 [==============================] - 0s 356us/step - loss: 29.5399\n",
      "Epoch 28/100\n",
      "299/299 [==============================] - 0s 336us/step - loss: 29.1758\n",
      "Epoch 29/100\n",
      "299/299 [==============================] - 0s 356us/step - loss: 28.6627\n",
      "Epoch 30/100\n",
      "299/299 [==============================] - 0s 323us/step - loss: 28.3610\n",
      "Epoch 31/100\n",
      "299/299 [==============================] - 0s 364us/step - loss: 27.9789\n",
      "Epoch 32/100\n",
      "299/299 [==============================] - 0s 335us/step - loss: 27.5319\n",
      "Epoch 33/100\n",
      "299/299 [==============================] - 0s 374us/step - loss: 27.2086\n",
      "Epoch 34/100\n",
      "299/299 [==============================] - 0s 356us/step - loss: 26.7240\n",
      "Epoch 35/100\n",
      "299/299 [==============================] - 0s 377us/step - loss: 26.4769\n",
      "Epoch 36/100\n",
      "299/299 [==============================] - 0s 346us/step - loss: 26.1120\n",
      "Epoch 37/100\n",
      "299/299 [==============================] - 0s 329us/step - loss: 25.7812\n",
      "Epoch 38/100\n",
      "299/299 [==============================] - 0s 401us/step - loss: 25.4693\n",
      "Epoch 39/100\n",
      "299/299 [==============================] - 0s 337us/step - loss: 25.1542\n",
      "Epoch 40/100\n",
      "299/299 [==============================] - 0s 353us/step - loss: 24.8392\n",
      "Epoch 41/100\n",
      "299/299 [==============================] - 0s 326us/step - loss: 24.5373\n",
      "Epoch 42/100\n",
      "299/299 [==============================] - 0s 360us/step - loss: 24.1984\n",
      "Epoch 43/100\n",
      "299/299 [==============================] - 0s 331us/step - loss: 23.9249\n",
      "Epoch 44/100\n",
      "299/299 [==============================] - 0s 348us/step - loss: 23.6528\n",
      "Epoch 45/100\n",
      "299/299 [==============================] - 0s 332us/step - loss: 23.4138\n",
      "Epoch 46/100\n",
      "299/299 [==============================] - 0s 369us/step - loss: 23.0888\n",
      "Epoch 47/100\n",
      "299/299 [==============================] - 0s 347us/step - loss: 22.8106\n",
      "Epoch 48/100\n",
      "299/299 [==============================] - 0s 356us/step - loss: 22.4372\n",
      "Epoch 49/100\n",
      "299/299 [==============================] - 0s 336us/step - loss: 22.3135\n",
      "Epoch 50/100\n",
      "299/299 [==============================] - 0s 358us/step - loss: 22.0214\n",
      "Epoch 51/100\n",
      "299/299 [==============================] - 0s 322us/step - loss: 21.6511\n",
      "Epoch 52/100\n",
      "299/299 [==============================] - 0s 345us/step - loss: 21.3616\n",
      "Epoch 53/100\n",
      "299/299 [==============================] - 0s 354us/step - loss: 21.04890s - loss: 15.\n",
      "Epoch 54/100\n",
      "299/299 [==============================] - 0s 386us/step - loss: 20.8091\n",
      "Epoch 55/100\n",
      "299/299 [==============================] - 0s 355us/step - loss: 20.4946\n",
      "Epoch 56/100\n",
      "299/299 [==============================] - 0s 363us/step - loss: 20.2515\n",
      "Epoch 57/100\n",
      "299/299 [==============================] - 0s 382us/step - loss: 20.0283\n",
      "Epoch 58/100\n",
      "299/299 [==============================] - 0s 392us/step - loss: 19.6940\n",
      "Epoch 59/100\n",
      "299/299 [==============================] - 0s 366us/step - loss: 19.4634\n",
      "Epoch 60/100\n",
      "299/299 [==============================] - 0s 379us/step - loss: 19.3218\n",
      "Epoch 61/100\n",
      "299/299 [==============================] - 0s 408us/step - loss: 18.9644\n",
      "Epoch 62/100\n",
      "299/299 [==============================] - 0s 338us/step - loss: 18.8502\n",
      "Epoch 63/100\n",
      "299/299 [==============================] - 0s 334us/step - loss: 18.5571\n",
      "Epoch 64/100\n",
      "299/299 [==============================] - 0s 385us/step - loss: 18.4381\n",
      "Epoch 65/100\n",
      "299/299 [==============================] - 0s 378us/step - loss: 18.1520\n",
      "Epoch 66/100\n",
      "299/299 [==============================] - 0s 369us/step - loss: 17.9502\n",
      "Epoch 67/100\n",
      "299/299 [==============================] - 0s 363us/step - loss: 17.8072\n",
      "Epoch 68/100\n",
      "299/299 [==============================] - 0s 343us/step - loss: 17.6306\n",
      "Epoch 69/100\n",
      "299/299 [==============================] - 0s 381us/step - loss: 17.4105\n",
      "Epoch 70/100\n",
      "299/299 [==============================] - 0s 368us/step - loss: 17.2205\n",
      "Epoch 71/100\n",
      "299/299 [==============================] - 0s 386us/step - loss: 17.0176\n",
      "Epoch 72/100\n",
      "299/299 [==============================] - 0s 352us/step - loss: 16.8429\n",
      "Epoch 73/100\n",
      "299/299 [==============================] - 0s 351us/step - loss: 16.6484\n",
      "Epoch 74/100\n",
      "299/299 [==============================] - 0s 369us/step - loss: 16.5054\n",
      "Epoch 75/100\n",
      "299/299 [==============================] - 0s 362us/step - loss: 16.3431\n",
      "Epoch 76/100\n",
      "299/299 [==============================] - 0s 338us/step - loss: 16.1645\n",
      "Epoch 77/100\n",
      "299/299 [==============================] - 0s 329us/step - loss: 16.0527\n",
      "Epoch 78/100\n",
      "299/299 [==============================] - 0s 327us/step - loss: 15.8567\n",
      "Epoch 79/100\n",
      "299/299 [==============================] - 0s 326us/step - loss: 15.7159\n",
      "Epoch 80/100\n",
      "299/299 [==============================] - 0s 330us/step - loss: 15.5596\n",
      "Epoch 81/100\n",
      "299/299 [==============================] - 0s 369us/step - loss: 15.4286\n",
      "Epoch 82/100\n",
      "299/299 [==============================] - 0s 375us/step - loss: 15.2739\n",
      "Epoch 83/100\n",
      "299/299 [==============================] - 0s 406us/step - loss: 15.1546\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 0s 383us/step - loss: 14.9988\n",
      "Epoch 85/100\n",
      "299/299 [==============================] - 0s 323us/step - loss: 14.8579\n",
      "Epoch 86/100\n",
      "299/299 [==============================] - 0s 322us/step - loss: 14.8080\n",
      "Epoch 87/100\n",
      "299/299 [==============================] - 0s 322us/step - loss: 14.6612\n",
      "Epoch 88/100\n",
      "299/299 [==============================] - 0s 323us/step - loss: 14.4913\n",
      "Epoch 89/100\n",
      "299/299 [==============================] - 0s 326us/step - loss: 14.4416\n",
      "Epoch 90/100\n",
      "299/299 [==============================] - 0s 365us/step - loss: 14.2530\n",
      "Epoch 91/100\n",
      "299/299 [==============================] - 0s 369us/step - loss: 14.1440\n",
      "Epoch 92/100\n",
      "299/299 [==============================] - 0s 361us/step - loss: 14.0081\n",
      "Epoch 93/100\n",
      "299/299 [==============================] - 0s 375us/step - loss: 13.9395\n",
      "Epoch 94/100\n",
      "299/299 [==============================] - 0s 372us/step - loss: 13.8036\n",
      "Epoch 95/100\n",
      "299/299 [==============================] - 0s 331us/step - loss: 13.6880\n",
      "Epoch 96/100\n",
      "299/299 [==============================] - 0s 319us/step - loss: 13.5851\n",
      "Epoch 97/100\n",
      "299/299 [==============================] - 0s 361us/step - loss: 13.5439\n",
      "Epoch 98/100\n",
      "299/299 [==============================] - 0s 383us/step - loss: 13.4323\n",
      "Epoch 99/100\n",
      "299/299 [==============================] - 0s 368us/step - loss: 13.2990\n",
      "Epoch 100/100\n",
      "299/299 [==============================] - 0s 376us/step - loss: 13.2279\n",
      "34/34 [==============================] - 1s 21ms/step\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 557.3403\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 0s 358us/step - loss: 539.2311\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 0s 348us/step - loss: 505.0510\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 453.2157\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 0s 345us/step - loss: 384.8608\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 0s 363us/step - loss: 306.0962\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 0s 371us/step - loss: 229.9154\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 168.4096\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 0s 393us/step - loss: 126.6338\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 0s 362us/step - loss: 100.3883\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 0s 413us/step - loss: 83.2685\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 0s 364us/step - loss: 71.1282\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 0s 344us/step - loss: 62.3182\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 55.4334\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 0s 326us/step - loss: 50.0930\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 0s 347us/step - loss: 45.8073\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 0s 367us/step - loss: 42.4407\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 0s 375us/step - loss: 39.9667\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 0s 381us/step - loss: 37.7237\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 35.9791\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 0s 361us/step - loss: 34.5709\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 0s 357us/step - loss: 33.3673\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 0s 347us/step - loss: 32.4084\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 0s 358us/step - loss: 31.6181\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 30.8127\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 0s 323us/step - loss: 30.0659\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 29.4971\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 0s 372us/step - loss: 28.9613\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 28.4896\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 0s 361us/step - loss: 27.8203\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 0s 392us/step - loss: 27.3513\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 0s 344us/step - loss: 26.8632\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 0s 350us/step - loss: 26.4446\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 25.9737\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 25.5800\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 0s 354us/step - loss: 25.2283\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 24.7855\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 24.4340\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 24.0618\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 0s 357us/step - loss: 23.7864\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 0s 403us/step - loss: 23.4119\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 23.2002\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 0s 366us/step - loss: 22.8763\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 0s 404us/step - loss: 22.4608\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 0s 383us/step - loss: 22.1721\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 0s 386us/step - loss: 21.8651\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 0s 345us/step - loss: 21.6023\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 21.3321\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 0s 323us/step - loss: 21.0618\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 0s 323us/step - loss: 20.8590\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 0s 326us/step - loss: 20.5436\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 20.3553\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 20.0797\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 0s 371us/step - loss: 19.9074\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 0s 374us/step - loss: 19.6292\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 19.4049\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 0s 368us/step - loss: 19.1563\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 0s 364us/step - loss: 18.9595\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 0s 362us/step - loss: 18.8065\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 0s 395us/step - loss: 18.5777\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 18.3369\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 0s 355us/step - loss: 18.1803\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 0s 323us/step - loss: 17.9952\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 0s 322us/step - loss: 17.8325\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 0s 356us/step - loss: 17.5819\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 17.4208\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 0s 393us/step - loss: 17.2918\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 0s 372us/step - loss: 17.1697\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 0s 379us/step - loss: 16.9737\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 0s 369us/step - loss: 16.7866\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 0s 411us/step - loss: 16.7318\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 0s 356us/step - loss: 16.4514\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 16.3485\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 16.2078\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 0s 378us/step - loss: 16.0680\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 0s 371us/step - loss: 15.8519\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 0s 374us/step - loss: 15.7597\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 370us/step - loss: 15.5936\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 0s 375us/step - loss: 15.4149\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 0s 369us/step - loss: 15.2921\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 15.1535\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 0s 357us/step - loss: 15.0407\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 14.8859\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 0s 324us/step - loss: 14.7749\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 14.6358\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 0s 369us/step - loss: 14.5106\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 14.4302\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 0s 347us/step - loss: 14.3075\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 0s 358us/step - loss: 14.2095\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 0s 369us/step - loss: 14.0555\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 14.0195\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 0s 323us/step - loss: 13.8340\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 0s 321us/step - loss: 13.8258\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 0s 323us/step - loss: 13.6644\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 13.5648\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 0s 379us/step - loss: 13.5001\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 0s 367us/step - loss: 13.4751\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 13.2869\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 13.1727\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 0s 386us/step - loss: 13.0840\n",
      "33/33 [==============================] - 1s 26ms/step\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 554.9593\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 543.2956\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 0s 323us/step - loss: 516.7608\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 470.6736\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 0s 325us/step - loss: 412.6991\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 0s 326us/step - loss: 349.2277\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 0s 323us/step - loss: 280.7582\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 0s 322us/step - loss: 215.4809\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 0s 323us/step - loss: 160.1598\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 0s 323us/step - loss: 118.1795\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 0s 324us/step - loss: 87.9895\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 0s 324us/step - loss: 68.2552\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 55.6414\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 0s 321us/step - loss: 47.2225\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 0s 324us/step - loss: 41.6982\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 0s 322us/step - loss: 37.7117\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 0s 324us/step - loss: 34.8822\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 0s 324us/step - loss: 32.5354\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 0s 321us/step - loss: 30.7715\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 29.2712\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 28.1765\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 27.1940\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 26.3797\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 25.6150\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 24.9592\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 24.4227\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 23.9598\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 23.4977\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 23.0736\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 22.6905\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 22.3411\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 22.1364\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 21.8349\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 21.5280\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 21.2015\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 20.9961\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 20.6992\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 20.5137\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 19.64 - 0s 332us/step - loss: 20.2666\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 20.0492\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 19.7025\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 19.5852\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 19.3155\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 19.1286\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 18.9053\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 18.6439\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 18.4787\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 18.2480\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 18.0885\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 17.9155\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 17.6861\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 17.5431\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 17.3395\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 17.2012\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 17.0391\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 16.8410\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 16.6782\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 0s 324us/step - loss: 16.5728\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 16.3804\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 16.1999\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 16.0541\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 15.8692\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 15.7190\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 15.5903\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 15.4078\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 15.2375\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 15.1010\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 14.9008\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 14.8417\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 14.6514\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 14.5231\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 337us/step - loss: 14.4064\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 0s 324us/step - loss: 14.2615\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 14.1870\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 0s 322us/step - loss: 14.0116\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 0s 319us/step - loss: 13.8879\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 0s 320us/step - loss: 13.8023\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 0s 326us/step - loss: 13.6258\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 0s 321us/step - loss: 13.6117\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 0s 326us/step - loss: 13.4117\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 0s 320us/step - loss: 13.3157\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 0s 324us/step - loss: 13.2168\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 0s 321us/step - loss: 13.1132\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 0s 320us/step - loss: 12.9783\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 0s 322us/step - loss: 12.8706\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 12.7744\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 12.7418\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 12.5885\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 0s 346us/step - loss: 12.4888\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 0s 320us/step - loss: 12.4257\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 12.3364\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 12.2172\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 12.1902\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 12.1850\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 12.0957\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 11.8867\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 0s 359us/step - loss: 12.0178\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 11.7935\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 0s 324us/step - loss: 11.7056\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 11.6233\n",
      "33/33 [==============================] - 1s 22ms/step\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 551.1269\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 531.7372\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 491.7685\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 427.4219\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 348.0691\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 267.7506\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 199.4750\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 149.1909\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 0s 363us/step - loss: 114.5236\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 0s 413us/step - loss: 91.4377\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 0s 348us/step - loss: 75.5382\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 64.0764\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 55.4667\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 0s 344us/step - loss: 48.9618\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 43.9631\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 40.3050\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 37.4450\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 35.1793\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 0s 346us/step - loss: 33.5737\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 32.2675\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 31.1050\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 0s 326us/step - loss: 30.2593\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 29.4245\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 28.6898\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 28.0932\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 27.5645\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 27.0526\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 26.5928\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 26.0645\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 0s 400us/step - loss: 25.6089\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 25.2293\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 24.8856\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 24.4686\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 24.0905\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 23.7235\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 23.3972\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 23.0467\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 22.6859\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 22.4129\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 22.1849\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 21.9219\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 21.5906\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 21.2796\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 0s 349us/step - loss: 21.0192\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 20.8512\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 20.4661\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 20.2891\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 19.9933\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 19.8223\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 19.6316\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 19.3561\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 19.1909\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 18.9558\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 18.7091\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 18.5540\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 18.3339\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 18.1238\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 17.9006\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 17.6901\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 17.5923\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 17.3459\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 17.2001\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 17.0354\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 16.8189\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 16.6636\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 332us/step - loss: 16.4799\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 16.4072\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 16.1827\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 16.0080\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 15.9437\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 15.6721\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 15.5444\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 15.3372\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 15.2248\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 15.0833\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 14.9132\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 14.8372\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 14.6361\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 14.5539\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 14.4201\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 14.2865\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 14.1367\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 13.9977\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 13.9835\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 13.8479\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 13.6945\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 13.6466\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 13.4663\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 13.4308\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 13.3442: 0s - loss: 14.647\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 13.2624\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 13.1333\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 13.0430\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 13.0021\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 12.9778\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 12.8479\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 12.7128\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 12.6027\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 12.5413\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 12.5128\n",
      "33/33 [==============================] - 1s 23ms/step\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 603.2362\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 0s 397us/step - loss: 587.7609\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 552.4329\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 495.7305\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 424.8696\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 346.0349\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 269.2978\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 200.0879\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 143.3249\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 104.6428\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 79.7603\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 64.7033\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 0s 349us/step - loss: 55.1966\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 48.9055\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 44.0644\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 40.4671\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 37.8264\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 35.7609\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 34.0817\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 32.6664\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 31.5032\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 30.5794\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 29.7364\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 28.9951\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 28.3055\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 27.8236\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 27.2631\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 26.8116\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 26.2953\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 25.8670\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 25.5172\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 25.1294\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 24.8213\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 24.4730\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 24.1299\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 23.9336\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 23.6682\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 0s 346us/step - loss: 23.3624\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 23.0734\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 22.7673\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 22.5836\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 22.3151\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 22.0946\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 21.8480\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 21.5981\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 21.4488\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 21.2766\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 21.1010\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 21.0197\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 20.6489\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 20.5280\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 20.3350\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 20.1852\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 19.9584\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 19.9132\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 19.63080s - loss: 18.13\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 19.5323\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 19.3298\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 19.1981\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 341us/step - loss: 19.0716\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 0s 325us/step - loss: 18.9572\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 18.7140\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 18.6290\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 18.4441\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 18.2620\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 18.1794\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 17.9702\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 17.8470\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 17.7778\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 17.6066\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 17.3773\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 17.3481\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 17.1996\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 17.1615\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 17.03830s - loss: 20.30\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 17.0461\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 16.7929\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 16.7420\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 16.5227\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 16.4415\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 16.3251\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 16.2616\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 16.1033\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 16.0382\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 15.9112\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 15.8257\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 15.7094\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 15.6495\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 15.5165\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 15.4412\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 15.3847\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 15.1589\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 15.1388\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 15.0669\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 14.9437\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 14.8175\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 14.7979\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 14.6462\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 14.4845\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 14.4629\n",
      "33/33 [==============================] - 1s 23ms/step\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 602.6411\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 582.3218\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 539.3892\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 474.1103\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 396.0091\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 315.7694\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 242.3464\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 183.4671\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 138.9475\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 106.8509\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 84.3547\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 68.1213\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 56.2001\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 47.3338\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 40.7598\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 0s 348us/step - loss: 35.8511\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 32.3232\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 29.6711\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 27.8988\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 0s 346us/step - loss: 26.5377\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 0s 327us/step - loss: 25.5182\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 24.7673\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 24.1755\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 23.7260\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 23.2039\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 22.8434\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 0s 347us/step - loss: 22.48380s - loss: 23.14\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 22.1156\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 21.7294\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 21.4153\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 21.1177\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 20.7810\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 20.4914\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 20.2256\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 19.9176\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 19.7634\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 19.4117\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 19.2222\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 18.9195\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 21.54 - 0s 327us/step - loss: 18.6722\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 18.4859\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 18.20030s - loss: 17.75\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 0s 349us/step - loss: 17.9636\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 17.7265\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 17.4875\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 17.2822\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 17.1476\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 16.9143\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 16.7611\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 16.5352\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 16.3088\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 16.1215\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 15.9393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 15.7918\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 15.5528\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 15.3748\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 15.1897\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 0s 345us/step - loss: 15.0690\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 14.8666\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 14.6646\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 14.5575\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 14.3256\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 14.1945\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 14.0509\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 13.9389\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 13.7117\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 0s 355us/step - loss: 13.5941\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 13.4590\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 13.2812\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 13.0902\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 12.9730\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 12.7957\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 12.6459\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 12.5129\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 12.3862\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 12.2169\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 0s 350us/step - loss: 12.1555\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 11.9461\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 0s 328us/step - loss: 11.7922\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 11.6833\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 11.5623\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 11.3334\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 11.2297\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 11.1259\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 11.0062\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 10.8489\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 10.7345\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 10.5604\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 10.4566\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 10.2640\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 10.2106\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 10.0347\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 9.8975\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 0s 329us/step - loss: 9.7778\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 9.6594\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 9.5526\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 9.4372\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 9.3433\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 9.1772\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 9.0871\n",
      "33/33 [==============================] - 1s 24ms/step\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 645.5525\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 0s 351us/step - loss: 630.5174\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 0s 364us/step - loss: 598.5059\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 0s 358us/step - loss: 543.1147\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 0s 345us/step - loss: 467.5562\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 378.4355\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 0s 343us/step - loss: 290.5602\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 214.8426\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 0s 344us/step - loss: 156.7408\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 0s 343us/step - loss: 116.4938\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 88.9208\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 0s 383us/step - loss: 71.1843\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 59.2690\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 51.0402\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 45.3095\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 41.4352\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 38.4766\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 36.4938\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 34.7871\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 33.4958\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 32.4684\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 31.7063\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 0s 345us/step - loss: 30.9239\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 30.2100\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 29.6477\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 0s 344us/step - loss: 29.0763\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 28.5598\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 28.1006\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 27.5533\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 27.1270\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 26.7586\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 26.3384\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 25.8930\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 25.5607\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 25.1500\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 24.8516\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 24.5060\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 24.1641\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 23.8666\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 23.5296\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 0s 343us/step - loss: 23.2117\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 22.9730\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 22.6508\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 22.3410\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 22.0857\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 21.7875\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 21.5811\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 341us/step - loss: 21.2792\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 20.9958\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 20.7909\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 20.5063\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 20.2434\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 19.9556\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 19.7589\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 19.4975\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 0s 330us/step - loss: 19.2543\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 19.0240\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 18.7601\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 18.5766\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 18.2541\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 18.1568\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 17.8634\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 17.6285\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 17.4675\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 17.1845\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 16.9646\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 16.8486\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 16.5514\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 0s 348us/step - loss: 16.3480\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 16.1124\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 15.9428\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 0s 331us/step - loss: 15.8089\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 15.5778\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 15.3421\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 15.1818\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 15.0574\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 14.8108\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 14.6525\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 14.4668\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 14.3245\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 14.1802\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 14.0593\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 13.9566\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 13.9007\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 13.6505\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 13.5334\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 13.5087\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 13.3230\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 13.2002\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 13.0801\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 12.9630\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 0s 332us/step - loss: 12.9253\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 12.7901\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 12.6887\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 12.5989\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 0s 333us/step - loss: 12.5793\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 12.4846\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 12.4388\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 12.2879\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 12.2435\n",
      "33/33 [==============================] - 1s 25ms/step\n",
      "Epoch 1/100\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 624.4765\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 0s 354us/step - loss: 610.2971\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 577.2626\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 521.2005\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 447.4180\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 367.9062\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 290.9995\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 223.6169\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 168.0176\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 125.8830\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 94.9188\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 73.0833\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 58.7261\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 49.1487\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 42.8221\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 0s 346us/step - loss: 38.3921\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 35.3792\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 33.1609\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 31.6368\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 0s 343us/step - loss: 30.3323\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 29.4340\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 0s 344us/step - loss: 28.6072\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 27.9571\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 27.5293\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 27.0307\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 26.6651\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 26.2588\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 0s 343us/step - loss: 25.9491\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 0s 344us/step - loss: 25.6799\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 25.4727\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 25.1916\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 24.8484\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 24.6935\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 24.4437\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 0s 347us/step - loss: 24.4723\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 0s 366us/step - loss: 24.0263\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 0s 345us/step - loss: 23.9322\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 23.7157\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 23.4946\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 23.3704\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 23.2585\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 338us/step - loss: 23.0090\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 0s 355us/step - loss: 22.9226\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 0s 366us/step - loss: 22.8085\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 0s 346us/step - loss: 22.5610\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 22.4333\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 22.2572\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 22.0758\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 0s 345us/step - loss: 21.9389\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 21.7853\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 0s 334us/step - loss: 21.5811\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 21.3725\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 21.2145\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 21.1268\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 20.8999\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 20.7920\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 20.6106\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 20.4052\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 0s 343us/step - loss: 20.3960\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 20.1441\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 20.0138\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 19.8116\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 19.6580\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 0s 346us/step - loss: 19.4903\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 19.3482\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 19.2343\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 19.0904\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 19.0389\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 18.8109\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 18.7367\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 18.6234\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 0s 342us/step - loss: 18.4889\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 18.3250\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 18.1185\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 17.9952\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 17.8792\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 17.6807\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 17.6470\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 17.4118\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 17.3012\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 0s 341us/step - loss: 17.2337\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 0s 339us/step - loss: 17.1005\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 16.9559\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 16.7940\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 16.6117\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 16.4708\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 0s 336us/step - loss: 16.3801\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 16.2252\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 0s 343us/step - loss: 16.0678\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 15.9300\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 15.7424\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 0s 344us/step - loss: 15.6600\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 15.5194\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 0s 335us/step - loss: 15.3596\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 15.2530\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 0s 337us/step - loss: 15.1263\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 0s 340us/step - loss: 15.0262\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 0s 350us/step - loss: 14.8960\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 0s 349us/step - loss: 14.7160\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 0s 338us/step - loss: 14.5959\n",
      "33/33 [==============================] - 1s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "estimator = [] \n",
    "# I want to put my steps into a pipeline where it is a list of tuples where each tuples has the steps I want to -\n",
    "# execute on the data in this case (1) standardization and then (2) creating the KerasRegressor model. \n",
    "# Inside each tuple I need an alias of the step I want to execute and then the actual step.\n",
    "\n",
    "estimator.append(('standardize', StandardScaler()))\n",
    "# appending this first tuple into the list where the first item is a string which is an alias for the step\n",
    "# the alias is 'standardize.' The step here is the StandardScaler().\n",
    "# The input to the skleran pipeline will be the predictors X and the target y. \n",
    "# These steps are the transformation done to the data.\n",
    "\n",
    "estimator.append(('keras_regessor', KerasRegressor(build_fn=sequential, epochs=100, batch_size=5)))\n",
    "# appending the model as the next step. The alias for this step is 'KerasRegressor'\n",
    "\n",
    "pipeline = Pipeline(estimator)\n",
    "# convert this list of tuples into a sklearn pipeline using Pipeline\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "# I seed it so that next time I can get back the exact 10 folds to replicate this experiment. \n",
    "\n",
    "results = cross_val_score(pipeline, X , y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -17.84062918,  -10.58787049,  -12.94601097,  -28.38946561,\n",
       "        -12.51909146,  -13.78073017,   -8.69279973, -118.06121081,\n",
       "        -30.91238517,  -29.29712011])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-28.30273136950219"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean() \n",
    "# the previous mse score without scaling was -38. Thus score here is 'reduced' now.\n",
    "# Not from a negative perspective. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.93226991580707"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune The Neural Network Topology\n",
    "\n",
    "QUOTE: There are many concerns that can be optimized for a neural network model.\n",
    "\n",
    "QUOTE: Perhaps the point of biggest leverage is the structure of the network itself, including the number of layers and the number of neurons in each layer.\n",
    "\n",
    "QUOTE: In this section we will evaluate two additional network topologies in an effort to further improve the performance of the model. We will look at both a deeper and a wider network topology.\n",
    "\n",
    "Topology: the way in which constituent parts are interrelated or arranged.\n",
    "1. This refers to the structure of the nerual network (1) The layers and the neurons.\n",
    "2. We want to change these structures (1) the depth of the hidden layer (2) the number of neurons and see how these things affect the result of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third model with an additional hidden layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(13, kernel_initializer='normal', activation='relu'))\n",
    "    # In the article the author only tried 6 neurons in this additional layer. \n",
    "    # I'm going to do 13 to keep it consistent. \n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasRegressor(build_fn=depth, epochs=100, batch_size=5, verbose=0)\n",
    "# Don't need the print out for each epoch thus putting verbose =0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the pipe\n",
    "pipe = []\n",
    "pipe.append(('standard_scaler', StandardScaler()))\n",
    "pipe.append(('keras_regressor', estimator))\n",
    "\n",
    "#converting the pipe into an sk_learn pipeline\n",
    "#model created\n",
    "sk_pipeline = Pipeline(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(sk_pipeline, X, y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -10.66504603,   -7.00351225,   -7.82824811,  -30.26593471,\n",
       "        -13.91890448,   -9.2671085 ,   -4.95140461, -114.25084103,\n",
       "        -26.26759389,  -20.46157883])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-24.488017243508136"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean() # the score of the previous model was -28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.99922540814344"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourth model with wider layers (more neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wider():\n",
    "    model = Sequential() #creating a sequantial model structure\n",
    "    model.add(Dense(20, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    # The initial neurons in the previous examples was 13. I'm gonna make it 20 to see what happens. \n",
    "    model.add(Dense(13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model with wrap\n",
    "estimator = KerasRegressor(build_fn=wider, epochs=100, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the pipt\n",
    "pipe = []\n",
    "pipe.append(('standard_scaler', StandardScaler()))\n",
    "pipe.append(('keras_regressor', estimator))\n",
    "\n",
    "sk_pipeline = Pipeline(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up KFold for cross_validation\n",
    "kfold = KFold(n_splits=10, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute cross_val_score\n",
    "\n",
    "results = cross_val_score(sk_pipeline, X, y, cv=kfold)\n",
    "\n",
    "# Do not that the only reason I can use an sk_learn pipeline here is because pipeline is a feature in sklearn.\n",
    "# cross_val_score is also a feature in sklearn thus they both work when used together\n",
    "# I can put the neural network model into the pipeline because I can already wrapped it in the KerasRegressor.\n",
    "# The model is represented as a function and put as an argument in the KerasRegressor wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -10.69306291,   -8.11226172,   -6.11200864,  -29.15501739,\n",
       "         -9.91375789,   -6.33576988,   -7.38632958, -111.82576168,\n",
       "        -30.55295131,  -21.29415174])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-24.13810727409288"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean() \n",
    "# not a significant imporvment since the previous model. \n",
    "# Previous model was -24.48\n",
    "# performance increase of 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-23.47489765903741"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the model with 2 layers of 20 neurons wide\n",
    "def wider():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(20, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "estimator = KerasRegressor(build_fn=wider, epochs=100, batch_size=5, verbose=0)\n",
    "\n",
    "pipe = []\n",
    "pipe.append(('standard_scaler', StandardScaler()))\n",
    "pipe.append(('keras_regressor', estimator))\n",
    "\n",
    "sk_pipeline = Pipeline(pipe)\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(sk_pipeline, X, y, cv=kfold)\n",
    "results.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENTS:\n",
    "\n",
    "1. Just with an additional neurons the model takes much longer to train on. Remember to always test your model on a shallower and narrower network topology first. If it works then scale it on Amazon Web Service.\n",
    "2. The results are not better than the previous. I guess there is a limit to how far you can try to optimize your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFL\n",
    "1. Most of the mistakes I make are from typos. As long as you are steady you are already faster even if you have nothing else to compare with. \n",
    "\n",
    "(1) casing (2) types (3) brackets (4) lacking the equal sign for when giving arguments (5) Lacking the name of the parameter.\n",
    "\n",
    "2. Missed out the name of the parameter. Always put it in as good practice. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
